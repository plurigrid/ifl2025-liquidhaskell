\documentclass[sigconf, anonymous, review]{acmart}
\citestyle{acmnumeric}
\usepackage[utf8]{inputenc}
\usepackage{fancyvrb}

%%%%%%%%%%%%%%%%% Editing marks %%%%%%%%%%%%%%%%%

  % TOGGLE ME to turn off all the commentary:
  \InputIfFileExists{no-editing-marks}{
    \def\noeditingmarks{}
  }

  \usepackage{xargs}
  \usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
  % ^^ Need for pgfsyspdfmark apparently?
  \ifx\noeditingmarks\undefined
      % Adapting to acmart's small margins
      \setlength{\marginparsep}{0.3em}
      \setlength{\marginparwidth}{1.4cm}

      \newcommandx{\unsure}[2][1=]{\todo[linecolor=orange,backgroundcolor=orange!25,bordercolor=orange,#1]{#2}}
      \newcommandx{\unsureF}[2][1=]{\todo[linecolor=orange,backgroundcolor=lightgray!25,bordercolor=orange,#1]{#2}}
      \newcommandx{\info}[2][1=]{\todo[linecolor=green,backgroundcolor=green!25,bordercolor=green,#1]{#2}}
      \newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
      \newcommandx{\inconsistent}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
      \newcommandx{\critical}[2][1=]{\todo[linecolor=purple,backgroundcolor=purple!25,bordercolor=purple,#1]{#2}}
      \newcommand{\improvement}[1]{\todo[linecolor=pink,backgroundcolor=pink!25,bordercolor=pink]{#1}}
      \newcommandx{\resolved}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}} % use this to mark a resolved question
    \else
      \renewcommand{\todo}{}
      \newcommandx{\unsure}[2][1=]{{}}
      \newcommandx{\unsureF}[2][1=]{{}}
      \newcommandx{\info}[2][1=]{{}}
      \newcommandx{\change}[2][1=]{{}}
      \newcommandx{\inconsistent}[2][1=]{{}}
      \newcommandx{\critical}[2]{{}}
      \newcommand{\improvement}[1]{{}}
      \newcommandx{\resolved}[2][1=]{{}}

  \fi

%%%%%%%%%%%%%%%%% /Editing marks %%%%%%%%%%%%%%%%%

\title{Interface design with SMT solvers: A study}

\author{undisclosed author/s}
\author{Facundo Dom√≠nguez}
\affiliation{
     \institution{Tweag}
     \country{Uruguay}
}
\email{facundo.dominguez@tweag.io}
\author{Arnaud Spiwack}
\affiliation{
     \institution{Tweag}
     \country{France}
}
\email{arnaud.spiwack@tweag.io}
\keywords{refinement types, Liquid Haskell, SMT solvers, library design}
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003752.10010124.10010138.10010142</concept_id>
       <concept_desc>Theory of computation~Program verification</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10010124.10010138.10010140</concept_id>
       <concept_desc>Theory of computation~Program specifications</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Theory of computation~Program verification}
\ccsdesc[500]{Theory of computation~Program specifications}

\newcommand{\tc}[1]{{\small\texttt{#1}}}
\newcommand{\codeblocksize}{\fontsize{6.5}{9}\selectfont}
\newcommand{\sourcefile}[1]{\anon[#1 (in the attached artifact)]{{\scriptsize\url{https://github.com/facundominguez/liquidhaskell/blob/fd/rapier/tests/rapier/#1}}}}
\RecustomVerbatimEnvironment{verbatim}{Verbatim}{
    fontsize=\codeblocksize,
}
\newtheorem{principle}{Principle}

\begin{document}
\begin{abstract}
    \change{Remember to make a pass on this abstract before submission}
    This paper explores the use of Satisfiability Modulo Theories (SMT) solvers,
    specifically through Liquid Haskell, to enhance static checks of
    programming language interfaces. Traditional approaches in strongly typed
    languages balance type richness with interface usability. We present a
    third alternative: leveraging SMT solvers via refinement types to offload
    static checks from the type checker. Our study includes a comparative
    analysis of capture-avoiding substitution, demonstrating the advantages of
    Liquid Haskell over type-checker-based methods. Furthermore, we investigate
    the application of SMT solvers to unification, a more complex scenario,
    highlighting both the capabilities and current limitations of this
    approach. We showcase modifications to Liquid Haskell to support these
    advanced checks, demonstrating technical feasibility. The paper also
    argues for the broad applicability of SMT solvers in ensuring various
    program properties, suggesting that their integration can significantly
    improve both the power and convenience of static checks in programming.
\end{abstract}
\maketitle

\section{Introduction}

SMT solvers are useful to the ordinary activity of
programming. This is what we would like to convince the reader of. More
precisely, our claim is that an SMT solver well-integrated in the static checks
of a compiler, complements an ordinary type checker when composing programs.

The experience of programming with types is that of collaborating with the
compiler to write the programs with want to write. SMT solvers can be use much
the same.

SMT solvers, when it comes to their application to programming, are usually
paired with terms like ``formal methods'' or ``verification'' in the
literature~\cite{barnett05,demoura08,zinzin17,swamy22}. We would like to
challenge the wisdom that we reach for SMT-solver-based tools when we need
formal methods. We would benefit from using SMT solvers in mundane programs.

We will be arguing, in particular, that refinement type, in the guise of Liquid
Haskell~\cite{vazou14b}, is a tool that lets you do just that. Even tough Liquid
Hakell is also usually invoked together with phrases like ``formal methods'' or
``verification''~\cite{vazou14,lehmann21,liu20,redmond23}. We would like to
challenge the wisdom that Liquid Haskell is only for formal method as well.

Through a case study, will we argue, even though the technology isn't really
ready yet, for a future where programming, ordinary programming, is made easier
and more pleasant thanks to refinements types and SMT solvers. Our case study,
will be the handling of binders' scopes in compilers. A secondary contribution
is a prototype implementation of a theory of finite maps for Liquid Haskell's
solver, to support our case study, and which we discuss in
Section~\ref{extending-liquid-haskell}.

\section{Capture-avoiding substitutions}
\label{capture-avoiding-substitution}

Binding scope management is recognized as a persistent annoyance when writing compilers.
It's easy to get wrong and is a source of mistake to the point that many have
proposed disciplines to prevent mismanagement of scopes, like name capture.
The poster child is substitution like in
$(\lambda x. y)[y:=t]$. The result of this substitution is $\lambda x. t$.
Thus $(\lambda x. y)[y:=x]$ is $\lambda x. x$. An easy mistake!

Compiler authors have proposed many discipline to help make scope more
manageable.
The GHC Haskell compiler, for instance, uses an approach to avoid name capture called
\textit{the rapier}~\cite{peytonjones02secrets}. All term-manipulating functions
carry an additional \textit{scope} set containing all the
variables that appear free in its arguments. This set is
used both to decide what to rename a binder to, in order to avoid name capture,
and it is also used to skip renaming a binder if it wouldn't capture any free
variables. Figure~\ref{rapier-style-substitution} shows an implementation of
substitution
for the untyped lambda calculus.

\begin{figure}
\begin{verbatim}
data Exp = Var Int | App Exp Exp | Lam Int Exp

substitute :: Set Int -> Subst Exp -> Exp -> Exp
substitute scope s e0 = case e0 of
  Var i -> case lookupSubst i s of Nothing -> e0; Just e -> e
  App e0 e1 -> App (substitute scope s e0) (substitute scope s e1)
  Lam i e
    | member i scope,
      let j = freshVar scope ->
        Lam j $ substitute (insert j scope) (extendSubst s i (Var j)) e
    | otherwise ->
        Lam i $ substitute (insert i scope) (extendSubst s i (Var i)) e

freshVar :: Set Int -> Int
freshVar s = case lookupMax s of Nothing -> 0; Just i -> i + 1
\end{verbatim}
\caption{Rapier style substitution}
\Description{Haskell implementation of substitution for untyped lambda terms using the rapier}
\label{rapier-style-substitution}
\end{figure}

\subsection{The foil}
\label{the-rapier-with-stronger-types}

The rapier wasn't enough, however, for \citet{maclaurin23} who report that
despite using the rapier they struggled with frequent scope issues in their
compiler. They set out to, enforce the scope properties of the rapier with
Haskell's type system. A stunt that has often been attempted, but
\cite{maclaurin23}'s approach, that they name \emph{the foil}, is probably the
first to succeed at enforcing such invariants without incurring an unreasonable
amount of boilerplate.

Here is our distillation of the properties that \citeauthor{maclaurin23} set
out to guarantee (see also \cite[Section~4]{maclaurin23}):
\begin{enumerate}
\item Every traversed binder must be added to the scope set, lest their name
      is later used instead of a fresh name.
\item \label{req:always-rename} Every traversed binder must be renamed if it's already a member of the
      scope set, because this name could otherwise be captured as above.
\item When renaming a binder, the new name must not belong to the scope set.
\item When renaming a binder, the occurrences of the old bound variable need
      to be substituted with the new name.
\item The initial scope set must contain the free variable of all the relevant
      arguments.
% \item The binders need to be removed from the domain of the substitution when
%       they are not in the scope set, otherwise the substitution will happily
%       replace occurrences of those bound variables! An alternative we use in
%       Figure~\ref{rapier-style-substitution} is to redefine the substitution to
%       map the variable of the binder to itself.
\end{enumerate}

\Citeauthor{maclaurin23} propose a library with types \tc{Scope n}, \tc{Name n}, and
\tc{Name\-Binder n l}. A value of type \tc{Scope n} is a set of names, where
the type index \tc{n} is the name of the set at the type level. A value of type \tc{Name n} is a name that
belongs to the set with type \tc{Scope n}. A value of type \tc{NameBinder n l} is
a name in the set with type \tc{Scope l} which results from adding such single
name to the set with type \tc{Scope n}. These types are to be used in
the abstract syntax tree of terms:

\begin{quotation}
\begin{verbatim}
data Exp n = Var (Name n)
           | App (Exp n) (Exp n)
           | forall l. Lam (NameBinder n l) (Exp l)
\end{verbatim}
\end{quotation}

Then the operations and type checking on the new types will guide the user into
respecting much of the scope requirements when implementing substitution.

\begin{verbatim}
substitute :: Distinct o => Scope o -> Subst Expr i o -> Expr i -> Expr o
\end{verbatim}

This type signature says that no names shadow each other in the scope set \tc{o}.
It also says that the substitution will take a expression with free variables in
a scope set \tc{i} and produce an expression with free variables in a scope set
\tc{o}.

There
are mechanisms to check that a scope set is a subset of another, to assert that no
name shadows another one in a given scope set, to reason that expressions
with free variables in one scope (\tc{Exp n}) can be coerced to expressions with
free variables in a superset (\tc{Exp l}), and to introduce scope sets that extend
others with freshly created names. They also provide an implementation of maps of
variables to expressions, that is the substitutions to apply, with an interface
that uses the new types as well. There is for instance the following function to
produce fresh variables:

\begin{verbatim}
withRefreshed
  :: Distinct o
  => Scope o
  -> Name i
  -> (forall (o' :: S). DExt o o' => NameBinder o o' -> r)
  -> r
\end{verbatim}

Using the constraint \tc{DExt}, this type signature says that scope set \tc{o'}
extends the scope set \tc{o} with the given \tc{NameBinder o o'}. This binder
may have the same name as the provided \tc{Name i} if it was not present in
\tc{o}, otherwise it will be a fresh name. As another example, the following
function always produces a fresh name.

\begin{verbatim}
withFresh
  :: Distinct n
  => Scope n
  -> (forall l . DExt n l => NameBinder n l -> r )
  -> r
\end{verbatim}

With ingenious engineering and design, the foil meets its rather ambitious goal.
But it is unfortunate that the authors needed to be ingenious. All things equal,
we prefer program components to be straightforward. Because ingenious solutions
take time, and because straightforward solutions are easier to adapt when the
parameters of the problem evolve.


\subsection{A Liquid Haskell primer}

We will turn next to Liquid Haskell as our proposed solution, but first let us
introduce Liquid Haskell briefly.
Liquid Haskell is a
plugin for Haskell which statically checks that programs respect signatures
provided by the programmer. There are two key differences between Liquid Haskell
signature checking and a classical type checker:

\begin{itemize}
  \item The checking process consists in generating logical assumptions which
        are then fed to an SMT solver, leveraging the powerful
        capabilities of SMT solvers to reason about numbers, arrays, strings, etc‚Ä¶
  \item Signatures are expressed with \emph{refinement types} of the form
        \tc{\{x:b | p\}}, which denotes values of type
        base type \tc{b} that satisfy predicate \tc{p}.
        Refinements are subject to subtyping in the same way as subsets in set
        theory, so that we have
\begin{verbatim}
{-@ f :: {x:Int | x > 1} -> {x:Int | x > 0} @-}
f :: Int -> Int
f x = x
\end{verbatim}
\end{itemize}

Liquid Haskell reads refinement type signatures and other annotations from
inside such special Haskell comments
\tc{\{-@ \ldots\ @-\}}. We will skip them in our snippets when it is unambiguous.

The predicates in the refinement types are in a language of expressions
referred to as the logic language. For the sake of this paper, we can
regard it as a subset of Haskell, except that predicates are assembled both from
regular Haskell functions and functions that are
only available in the logic language.

A function like \tc{member}, which comes from the module \tc{Data.Set}
in the \tc{containers} package, is linked by Liquid Haskell to the
SMT solver's theory of sets.
\begin{verbatim}
import Data.Set
assume member :: Ord a
              => x:a -> xs:(Set a) -> {v:Bool | v <=> Set_mem x xs}
\end{verbatim}
Refinement type signatures starting with the \tc{assume} keyword declare that the
corresponding Haskell function honors the signature, but it isn't
checked. In this case it's because \tc{Data.Set} is an external dependency that
Liquid Haskell can't check. But it can also be applied to our own functions.

Here \tc{Set\_mem} is a special function that Liquid Haskell maps to the theory
of sets in the SMT solver.\unsure{I hope I'm not lying here. Please factcheck
  me.} While that \tc{member} verifies this signature isn't checked, Liquid
Haskell will assume this property whenever \tc{member} is used in a program.
That is Liquid Haskell will know that \tc{member} is Haskell's implementation of
set membership.\change{member is not too simple an example because it has two dimensions.
On the one hand, there is the assumed refinement type, which is used to prove
properties about code that uses member. On the other hand, there is the
\tc{define} annotation, that is used when translating functions that use member to the
logic. I feel the statement that LH links \tc{member} and \tc{Set\_mem} is only partly
true if you only have the assumed signature.}

Notice how the predicate on the return type mentions both arguments. Liquid
Haskell lets us express refinement types which relate arguments with each other,
and with the result in this manner. This obviates the need, in particular, to
give a type-level name to arguments using existential quantification.

To define purely logic function, Liquid Haskell uses the \tc{measure} keyword,
such as:\improvement{Unfortunately, I couldn't think of a measure from the
  Liquid Haskell standard library that we use. So I resorted to take a random
  one from Set instead (which is also the only one from Set).}
\begin{verbatim}
measure listElts :: [a] -> Set a
  listElts []     = {v | (Set_emp v)}
  listElts (x:xs) = {v | v = Set_cup (Set_sng x) (listElts xs) }
\end{verbatim}

It is also possible to define uninterpreted symbols by simply omitting the
definition. It would look like this
\begin{verbatim}
measure listElts :: [a] -> Set a
\end{verbatim}
The meaning of the function would then be given by \tc{assume} refinement
signature on other functions.

\subsection{The rapier, refined}
\label{the-rapier-with-refinement-types}

We would, now, like to argue that using Liquid Haskell to enforce the
requirements from Section~\ref{the-rapier-with-stronger-types} is more
straightforward than using the type system. The code presented in this section is available in the file
\tc{Subst1.hs}.\footnote{The simplest approach with Liquid Haskell:
  \sourcefile{Subst1.hs}}

In order to deal with scope checks, we first define a type alias \tc{ScopeExp S},
that is the type of all
expressions whose free variables are in the set \tc{S}\footnote{In type aliases,
Liquid Haskell expects parameter names to start with an uppercase letter.}.

\begin{verbatim}
{-@ type ScopedExp S = {e:Exp | isSubsetOf (freeVars e) S} @-}
\end{verbatim}

Functions like \tc{isSubsetOf} and \tc{difference} come from the \tc{Data.\allowbreak Set}
module. The function \tc{freeVars} is in the same module as \tc{subs\-ti\-tute},
and collects the free variables of an expression. We note that this function
is only used in refinement type signatures, and in particular, it is not evaluated
when calling to \tc{substitute}.

\begin{verbatim}
freeVars :: Exp -> Set Int
freeVars e = case e of
  Var i -> singleton i
  App e1 e2 -> union (freeVars e1) (freeVars e2)
  Lam i e -> difference (freeVars e) (singleton i)
\end{verbatim}

Next, we need to give the following refined signature to the \tc{freshVar} of
Figure~\ref{rapier-style-substitution}:
\begin{verbatim}
{-@ assume freshVar :: s:Set Int -> {v:Int | not (member v s)} @-}
\end{verbatim}
This signature is assumed rather than checked. We could choose to check it, but
Liquid Haskell doesn't have a good built-in understanding of the \tc{lookupMax}
function that we use. So instead, we choose to assume the signature. This is our
first principle of programming with refinement types:

\begin{principle}
  Refinement types permit a smaller trusted code base than
  abstract types, but offer you a choice. When its easier to prove a result by
    hand than with the SMT solver, you should assume the property.\improvement{I feel
    this principle needs a discussion of unsafe coercions. Are unsafe coercions the
    way to assume properties with abstract types? Then they also offer a choice as
    Liquid Haskell does. If unsafe coercions aren't such a good choice, why not?}
\end{principle}

That's it, this is the entirety of our trusted code base for this example. For
the most part, it required thinking about what properties we wanted to enforce,
but not much about how they ought to be enforced.\change{Aren't \tc{lookupSubst}
and \tc{extendSubst} part of our trusted code base too? If they aren't, I think
it would need to be explained. If they are, this account of the trusted code base
should be moved further below.}

Finally, we assume that we have some datatype representing substitutions
(\emph{i.e.} finite maps of variables to terms), although we don't require any
particular implementation: this datatype is a parameter of our algorithm. To
that effect we assume an opaque data type and axiomatize its supporting
functions.

\begin{verbatim}
data Subst t -- opaque
{-@ measure domain :: Subst e -> Set Int @-}

assume lookupSubst
  :: k:Int
  -> xs:Subst e
  -> {m:Maybe e | isJust m == member k (domain xs) }

assume extendSubst
  :: s:Subst a
  -> i:Int
  -> a
  -> {v:_ | union (domain s) (singleton i) = domain v }
\end{verbatim}

Notice that the logical function \tc{domain}, which stands for the set of
variables that the substitution defines, is uninterpreted. It must be since it's an
assumption.\unsure{Something which could be part of the discussion
  section at the end of the article, I think, is how do you actually instantiate
  these axioms with an concrete substitution type? Answer: Sounds good, you copy
  the assumptions to address whatever substitution representation is needed.}

We can give now the following signature to \tc{substitute}
\begin{verbatim}
{-@
substitute
  :: scope:Set Int
  -> s:Subst (ScopedExp scope)
  -> ScopedExp (domain s)
  -> ScopedExp scope
@-}
substitute :: Set Int -> Subst Exp -> Exp -> Exp
\end{verbatim}
Remarkably, the implementation for \tc{substitute} is unchanged from the
implementation, without static scope checking, of
Figure~\ref{rapier-style-substitution}. This won't always be the case, but this
exemplifies how using Liquid Haskell to enforce invariants tends to create less
boilerplate than a type-based approach.

Figure~\ref{rapier-style-substitution} uses that a substitution
\begin{verbatim}
s :: Subst (ScopedExp scope)
\end{verbatim}
also has (refined) type
\begin{verbatim}
s :: Subst (ScopedExp (insert i scope))
\end{verbatim}
This kind of subtyping is trivial with refinement types, it's the default
behavior. Whereas with an ML type system, subtyping isn't a typical feature. The
foil, for instance, needs an explicit function to cast substitutions when
extending a scope. This is our next principle:
\begin{principle}
  Refinement types add a layer of subtyping on top of your type system. When
  your program is best modeled with subtyping you should consider refinement
  types.
\end{principle}

The type of lambda terms is also unchanged, as the well-scoping invariant is
applied to a whole term at once. A nice consequence of that is that functions
that don't benefit from all the scope checking business can simply take a naked
term and ignore it. The \tc{freeVars} function, for example, is implemented on
naked terms.\unsure{I'm considering adding a comment on the fact that we can use
  freeVars to provide an initial scope for the substitute function. Note:
  the foil starts with an identity substitution, that is, one that maps every
  variable to itself. And we do the same in our unification code. The substitution
  domain can be narrowed if desired, but starting with the identity doesn't affect
  the static checks.}

\subsection{A hybrid approach}
\label{ensuring-the-scope-set-is-checked}

Our refinement type signature of \tc{substitute} follows the type signature of
\citeauthor{maclaurin23} to the letter.
Yet we can introduce the following bug in \tc{substitute} from
Figure~\ref{rapier-style-substitution}:
\begin{verbatim}
  ...
  | member i scope ->
      Lam i $ substitute (insert i scope) (extendSubst s i (Var i)) e
\end{verbatim}
Liquid Haskell flags no errors but the program will still misbehave as
follows (in pseudo-Haskell).

$$\codeblocksize{\tc{substitute}~\{\tc{x}\}~(\lambda{}\tc{x}. \tc{y}) [\tc{y}:=\tc{x}] = (\lambda{}\tc{x}. \tc{x})}$$

What is going on? The binder \tc{i} is now capturing free variables in the
range of the substitution. The signature is, in fact, indifferent to whether
the binder \tc{i} is already present or not in the scope set. There's no
mechanism to prevent adding a binder that is already present in the scope set.
That is, we fail to enforce Property~(\ref{req:always-rename}) from Section~\ref{the-rapier-with-stronger-types}.
And, more to the point, how could we? ‚ÄúNever add a binder to the scope set that is already
present‚Äù isn't a set theoretical property. It's not even a functional property.
It is a kind of temporal invariant.

Such temporal invariants aren't naturally expressed in the logic of Liquid Haskell.
But they're quite easy to implement with abstract types. So let's use an abstract
type. What we need to do is to ensure that whenever we see a new binder it must
be tested against the scope, and that this test is packaged together with fresh
name generation.

We follow the foil and
introduce an abstract type \tc{Scope} and a function \tc{withRefreshed}. The types are a little
simpler because we don't need existential quantification to reflect value-level
objects at the type level, but otherwise these are the same functions and types
as in Section~\ref{the-rapier-with-stronger-types}.
\begin{verbatim}
newtype Scope = UnsafeScope { unsafeUnScope :: (Set Int) }
{-@
predicate Member E S = Set.member E (unsafeUnScope S)

withRefreshed :: s:Scope -> i:Int
  -> {p:(Scope, Int) |
       not (Member (snd p) s) && fst p == union s (singleton (snd p))}
@-}
withRefreshed :: Scope -> Int -> (Scope, Int)
withRefreshed (UnsafeScope s) i
  | Set.member i s = let j = freshVar s in (UnsafeScope (insert j s), j)
  | otherwise = (UnsafeScope (insert i s), i)
\end{verbatim}

We needed to add a refinement type signature to \tc{withRefreshed} to serve as
glue with the Liquid Haskell world. This refinement type signature tells Liquid
Haskell precisely that \tc{withRefreshed} does both membership checking and
fresh variable call: the variable returned by \tc{withRefreshed} isn't in the
old scope but is in the new scope.

It then suffices to seal the type \tc{Scope} to enforce that binders are always
refreshed when traversed.\change{Here we need a discussion of what sealing means,
which could be the place to discuss the need for the Member predicate alias as well.}
The full code for this example can be found in the
file \tc{Subst2.hs}.\footnote{A solution with a sealed scope type: \sourcefile{Subst2.hs}}

This is our next principle for refinement types:
\begin{principle}
  Refinement types and abstract types are best at enforcing different kind of
  properties. You should user the simpler solution for each property that you
  need, as refinement types and abstract types mix well.
\end{principle}

% The second approach, avoid introducing \tc{withRefreshed} and modifying the
% types in the program by providing a more stringent refinement type for
% \tc{substitute}.

% \begin{verbatim}
% substitute
%   :: scope:Set Int
%   -> s:Subst (ScopedExp scope)
%   -> ei:ScopedExp (domain s)
%   -> {v:Exp | freeVars v == freeVarsSubst (freeVars ei) s}
% \end{verbatim}

% In this signature we are spelling exactly what the expected free variables in the result are.
% We use a function \tc{freeVarsSubst} such that
% \tc{freeVarsSubst (freeVars e) s} computes the free variables in the range of the
% substitution \tc{s} that is actually used when applying it
% to the expression \tc{e}. We provide an example representation for substitutions and
% a schematic presentation of \tc{freeVarsSubst}, but in our implementation we
% are careful to keep the checks agnostic on the actual representation of
% substitutions.

% \begin{verbatim}
% type Subst e = [(Int, e)]
% freeVarsSubst :: Set Int -> Subst Exp -> Set Int
% freeVarsSubst used [] = empty
% freeVarsSubst used ((i, e) : xs) =
%   | member i used = -- only take the first occurrence of i
%       union (freeVars e) (freeVarsSubst (difference used (singleton i)) xs)
%   | otherwise = freeVarsSubst used xs
% \end{verbatim}

% Unless we rename all the binders unconditionally, it is no longer
% possible to ignore the scope set when going under binders since the calculation
% of free variables doesn't add up:
% If the name of the binder is in the free variables of the range of the substitution,
% it may show up in the free variables of the result, but leaving it unrenamed would
% cause the call to the function \tc{freeVars} in the expected return refinement type
% to disagree.

% Unfortunately, this refinement type signature is more laborious to check, as
% \tc{free\-Vars\-Subst} requires roughly one lemma per case of the \tc{subs\-ti\-tute}
% function.

% \begin{verbatim}
% lemmaFreeVarsSubstSing :: i:_ -> s:_
%   -> { freeVarsSubst (singleton i) s == fromMaybe empty (lookupSubst i s) }

% lemmaFreeVarsSubstUnion :: s1:_ -> s2:_ -> s:_
%   -> { freeVarsSubst (union s1 s2) s
%          == union (freeVarsSubst s1 s) (freeVarsSubst s2 s) }

% lemmaFreeVarsSubstExtend
%   :: scope:_ -> used:_
%   -> i:_ -> {e:_ | Data.Set.null (intersection (freeVars e) scope)}
%   -> s:Subst (ScopedExp scope)
%   -> { freeVarsSubst (difference used (singleton i)) s ==
%        difference (freeVarsSubst used (extendSubst s i e)) (freeVars e)
%      }
% \end{verbatim}

% Each lemma requires writing a recursive function for Liquid Haskell to
% check it, which is additional effort. Here's the proof for
% \tc{lemma\_free\-Vars\-Subst\_union}.

% \begin{verbatim}
% lemmaFreeVarsSubstUnion :: Set Int -> Set Int -> Subst Exp -> ()
% lemmaFreeVarsSubstUnion _ _ [] = ()
% lemmaFreeVarsSubstUnion s1 s2 ((i, _) : xs) =
%   lemmaFreeVarsSubstUnion
%     (difference s1 (singleton i)) (difference s2 (singleton i)) xs
% \end{verbatim}

% The recursive function follows the structure of an inductive proof,
% with much of the folding, unfolding, and set properties applied
% automatically. And this is similar for the proofs of the other lemmas.
% Then the lemmas need to be applied in the cases of \tc{substitute}.

% \begin{verbatim}
% substitute scope s e0 = case e0 of
%   Var i -> case lookupSubst i s of
%     Nothing -> e0
%     Just e -> e ? lemmaFreeVarsSubstSing i s
%   App e0 e1 ->
%     App (substitute scope s e0) (substitute scope s e1)
%       ? lemmaFreeVarsSubstUnion (freeVars e0) (freeVars e1) s
%   Lam i e
%     | member i scope,
%       let j = freshVar scope ->
%         Lam j $ substitute (insert j scope) (extendSubst s i (Var j)) e
%           ? lemmaFreeVarsSubstExtend scope (freeVars e) i (Var j) s
%     | otherwise ->
%         Lam i $ substitute (insert i scope) (extendSubst s i (Var i)) e
%           ? lemmaFreeVarsSubstExtend scope (freeVars e) i (Var i) s
% \end{verbatim}

% The operator \tc{?} is an alias for function \tc{const = \textbackslash x \_ -> x} and
% brings the lemma into consideration of Liquid Haskell when checking the
% first argument without evaluating the recursive function that stands for
% the lemma proof. This solution is available in the file
% \tc{Subst3.hs}\footnote{A solution that addresses all requirements without
%   changing types in the program: \sourcefile{Subst3.hs}}\change{A single Subst
%   file please}
% in our repository.


\subsection{Comparison}

When using Liquid Haskell we needed to implement the
\tc{freeVars} function, provide the \tc{ScopedExp} refined type, and the refinement
type signatures of the substitution primitives. Contrast with an abstract-type based
approach where a lot primitives must be provided by the abstract interface. The foil,
in particular, needs several types, type classes, and primitive functions.
\unsureF{Shall we discuss here that LH is checking a slightly different set of properties?
We don't check property (2), but we do check that non-renamed binders are removed from
the domain of the substitution, which the foil leaves to the trusted code.}

\unsure{[Arnaud] I'm not sure yet whether I prefer this subsection to be here,
  or together with the evaluation section.}
Liquid Haskell ensures most requirements with little assistance
because it is delegating much of the work to an underlying SMT solver.
SMT solvers are tools that decide whether (usually first order) logic formulas are
satisfiable and provide dedicated mechanisms to reason about various theories
(sets, strings, arrays, integers, reals, etc).

In the case of capture-avoiding substitution, multiple queries that
Liquid Haskell gives to the SMT solver involve reasoning on sets, thus
making effective use of its capabilities. Moreover, the expression of
relationships between arguments and result is fairly natural with
refinement types. When there are lemmas to prove, despite of being
additional effort to write, they still have proofs that don't require
a lot of creativity.

On the other hand, an approach like the foil does need the author to
think carefully about how to encode the various static checks with the
type checker, a non trivial supporting library needs to be written,
and the effort might need further iterations when accounting for
additional properties.
We will return to this latter aspect in Section~\ref{SMT-solvers-for-interface-checks}.


\section{Unification}
\label{unification}

Now that we have established the refined rapier interface, let us show how it
can be applied to a more realistic example: solving first-order equational
formulas. Specifically, we'll be solving a form of hereditary Harrop formulas~\cite{miller91} in
the Herbrand domain. This is the sort of unification problem which can show up
when typechecking programs with GADTs~\cite{schrijvers09}. Scope management in
such a solver is a much trickier business than in the case of mere substitutions
and, in the authors' experience, something where any help from the compiler is welcome.
The source code of this section can be found in the file
\tc{Unif.hs}.\footnote{Source code of unification: \sourcefile{Unif.hs}}

In addition to variables, still represented as integers, we have unification
variables. Unification variables have their own scope: the formula
$\exists x. \forall y. x=y$ doesn't have a solution. It will be reduced to a
formula of the form $f_{x} = y$ where $f_{x}$ is a unification variable; we very much
don't want this unification problem to succeed\improvement{I think we should
  use a better notation to distinguish unification variables from rigid
  variables.}: we shall make it so that $y$ isn't in the permissible scope for $f_{x}$.

Furthermore, we will perform substitutions, substitutions are blocked by
unification variables as we don't know what they stand for yet. So a unification
variable, in our syntax, is a pair $(f, [x_0:=t_0,\ldots,x_n:=t_n])$ of a
unification variable proper and a suspended substitution. Where
$\{x_0,\ldots,x_{n}\}$ is the scope of $f$. Such a pair is akin to a skolem
function application $f(t_0,\ldots,t_n)$. Notice in particular, how the solution
of $f$ can only have free variables in $\{x_0,\ldots,x_{n}\}$, but
$(f, [x_0:=t_0,\ldots,x_n:=t_n])$ may live in a different scope altogether. This
is what makes this type of unification problem tricky.

\begin{verbatim}
type Var = Int
type SkolemApp = (Var, Subst Term)
\end{verbatim}

This way, our formula $\exists x. \forall y. x=y$ will be reduced to
$(f_{x},[]) = y$ which doesn't have a solution. On the other hand
$\forall x. \exists y. x = y$ becomes $x = (f_{y}, [x:=x])$ so $x$ is a solution
for $f_{y}$ and the formula is solvable.

\begin{verbatim}
data Term
  = V Var | SA SkolemApp | U | L Term | P Term Term deriving

data Formula
  = Eq Term Term               -- equality
  | Conj Formula Formula       -- conjunctions
  | Then (Term, Term) Formula  -- a = b => f
  | Exists Var Formula         -- existential quantification
  | Forall Var Formula         -- universal quantification
\end{verbatim}

Our term language allows for variables, skolem applications, and some artificial
data constructors (i.e. injective functions). The language of formulas has
equality, conjunction, existential and universal quantification, and it also
has a form of implication that only allows for equalities in the antecedent.
The conception is driven by the simplest language that still would allow to
express something of practical interest like constraints of generalized
algebraic data types (GADTs)~\cite{schrijvers09}.

Our unification algorithm is then expressed in Figure~\ref{conditional-unification}.
The function \tc{unify} takes a scope parameter containing all the variables that
can appear free in the input formula. This set is useful to rename \tc{Forall}
binders when doing substitutions. For instance, unifying the following formula
$$\forall x. \forall y. \exists z. y = L(x) \Rightarrow \forall x. y = z$$
reduces to unifying
$$\forall x. \forall y. \exists z. (\forall x. y = z)[y:=L(x)]$$
and the substitution needs to rename the inner binder $x$.

There is a preceding pass, not shown in the figure, which replaces existential variables
with skolem applications. We have functions \tc{substituteFormula} and \tc{substitute}
to apply substitutions in formulas and terms, \tc{substituteSkolems} to  substitute
skolems in formulas. We have a function \tc{skolemSet} to collect the skolems of a
term. And a function \tc{fromListSubst} to construct a substitution from a list of
pairs \tc{[(Var, Term)]}.

The functions \tc{substEq} and \tc{unifyEq} are slightly more complex in the source files
as they also deal with the data constructors of our \tc{Term} language, but they are
not essential to the discussion in this section.

\begin{figure}
\begin{verbatim}
unify :: Set Int -> Formula -> Maybe [(Var, Term)]
unify s (Forall v f) = unify (Set.insert v s) f
unify s (Exists v f) = error "unify: the formula hasn't been skolemized"
unify s (Conj f1 f2) = do
    unifyF1 <- unify s f1
    unifyF2 <- unify s (substituteSkolems f2 unifyF1)
    return (unifyF1 ++ unifyF2)
unify s f@(Then (t0, t1) f2) =
    let subst = fromListSubst (substEq t0 t1)
     in unify s (substituteFormula s subst f2)
unify s (Eq t0 t1) = unifyEq t0 t1

substEq :: Term -> Term -> [(Var, Term)]
substEq (V i) t1 = [(i, t1)]
substEq t0 (V i) = [(i, t0)]
substEq _ _ = []

unifyEq :: Term -> Term -> [(Var, Term)]
unifyEq t0 t1@(SA (i, s))
  | Just s' <- inverseSubst $ narrowForInvertibility (freeVars t0) s
  , let t' = substitute s' t0
  , not (Set.member i (skolemSet t'))
  , Set.isSubsetOf (freeVars t') (domain s)
  = [(i, t')]
unifyEq t0@(SA _) t1 = unifyEq t1 t0
unifyEq _ _ = []

-- | @narrowForInvertibility vs s@ removes pairs from @s@ if the
-- range is not a variable, or if the range is not a member of @vs@.
narrowForInvertibility :: Set Var -> Subst Term -> Subst Term
narrowForInvertibility vs (Subst xs) =
  Subst [(i, V j) | (i, V j) <- xs, Set.member j vs]

inverseSubst :: Subst Term -> Maybe (Subst Term)
inverseSubst (Subst xs) = fmap Subst (go xs)
  where
    go [] = Just []
    go ((i, V j) : xs) = fmap ((j, V i) :) (go xs)
    go _ = Nothing
\end{verbatim}
\caption{Conditional unification}
\Description{Haskell implementation of condition unification}
\label{conditional-unification}
\end{figure}

The function \tc{unifyEq} defines what a good solution should be.
One of the conditions is that whatever term \tc{t'} is proposed
as solution for a skolem \tc{i}, it needs to have as free variables only those in the
domain of the substitution defining the skolem application
(\textit{scope check}). Another
condition is that the skolem \tc{i} should not occur in the solution
\tc{t'} (\textit{occurs check}). And since we are inverting a substitution to find
\tc{t'}, we might not find solutions if we cannot invert the
substitution. This implementation only inverts substitutions where
variables are mapped to variables. That is, we solve $(f, [z:=x]) = L(L(x))$
to get the solution $(f, L(L(z)))$ but we do not try solving $(f, [z:=L(x)]) = L(L(x)))$.


\subsection{A look at skolemization}

Figure~\ref{skolemization} shows the function to replace existential quantifiers
with unification variables. This example is interesting because the complexity of
managing two different scopes for universal and existential quantifiers
respectively exceeds considerably the canonical example of the rapier.

\begin{figure}
\begin{verbatim}
skolemize :: Set Int -> Formula -> State (Set Int) Formula
skolemize sf (Forall v f) = do
    se <- get
    put (Set.insert v se)
    f' <- skolemize (Set.insert v sf) f
    pure (Forall v f')
skolemize sf (Exists v f) = do
    se <- get
    let u = if Set.member v se then freshVar se else v
    put (Set.insert u se)
    let subst = fromListSubst [(v, SA (u, fromSetIdSubst sf))]
    skolemize sf (substituteFormula sf subst f)
skolemize sf (Conj f1 f2) = do
     f1' <- skolemize sf f1
     f2' <- skolemize sf f2
     pure (Conj f1' f2')
skolemize sf (Then (t0, t1) f2) = do
     f2' <- skolemize sf f2
     pure (Then (t0, t1) f2')
skolemize _ f@Eq{} = pure f
\end{verbatim}
\caption{Skolemization}
\Description{Haskell implementation of skolemization}
\label{skolemization}
\end{figure}

To begin with, the function takes a set \tc{sf} of variables that have been
introduced with universal quantification, and that can appear free in the
input formula. The set \tc{se} in the monadic state contains the variables
that have been introduced with existential quantification \tc{se}.

We expect the set \tc{sf} to be a subset of \tc{se}. This is to reflect the
fact that we don't want unification variables to be called the same as
universally quantified variables. It is not a strict requirement, but one
that makes the output of \tc{skolemize} considerably easier to read.

We also really need to put the set \tc{se} in the monadic state, as we don't
want to generate the same unification variable for existentials appearing
on different subformulas. For instance, the following formula
$$\forall x. \exists y. x = y \land \forall z. \exists y. z = y$$
should produce unification variables like
$$\forall x. x = y[x:=x] \land \forall z. z = w[x:=x, z:=z]$$
It would be a mistake to call both unification variables $y$ and $w$ the same,
as their occurrences have different scopes!

Lastly, we do need to keep the scope set \tc{sf} separate from the monadic
state because it is needed to construct the skolem function applications where
existential variables are found.

Here is the refinement type signature of \tc{skolemize}.
\begin{verbatim}
skolemize
  :: sf:_
  -> {f:ScopedFormula sf | consistentSkolemScopes f}
  -> State
       < {\se0 ->
             isSubsetOf sf se0
          && isSubsetOf (IntMapSetInt_keys (scopes f)) se0
         }

       , {\se0 v se ->
             consistentSkolemScopes v
          && existsCount v = 0
          && isSubsetOf (freeVarsFormula v) sf
          && isSubsetOf se0 se
          && Set.empty =
               intersection
                 se0
                 (IntMapSetInt_keys
                    (IntMap.difference (scopes v) (scopes f)))
          && intMapIsSubsetOf (scopes f) (scopes v)
          && isSubsetOf (IntMapSetInt_keys (scopes v)) se
       }>
       _ _
     / [formulaSize f]
\end{verbatim}
Preconditions on the state set \tc{se0} come between a first pair of braces,
and postconditions on the return value and the output state \tc{se} come in
a second pair of braces. Refinement types for the State monad are not readily
available in Liquid Haskell, but they can be put together from examples in
the project test suite. We provide our recollection of it in the file
\tc{State.hs}.\footnote{Refinment type support for the State monad: \sourcefile{State.hs}}.

The logic function \tc{IntMapSetInt\_keys} is part of the extension to Liquid
Haskell that we discuss in Section~\ref{extending-liquid-haskell}. It provides
a set containing the keys of a given \tc{IntMap}.

The postconditions that are most important for users of \tc{skolemize} are
\tc{consistentSkolemScopes v} and \tc{existsCount v = 0}, meaning that no
existential quantifier remains, and that every occurrence of a given
unification variable has the same scope. These are exactly the requirements
of the refinement type signature of \tc{unify} to come in Section~\ref{checking-unify}.
\unsureF{If this subsection is to stay, and to stay at this place, we may have to
move the introduction of these and other functions here. But I think it needs
your assessment before taking the trouble.}
The rest of the postconditions are invariants needed during the recursion
to check the first two.
We leave the encoding of these properties in the Haskell type system as an
exercise for the reader.

We won't discuss the checking process for this function, as examples follow
which  don't require the burden of explaining the mechanisms for
checking monadic code. But we do note that all the cases of the function
\tc{skolemize} are checked as it appears in Figure~\ref{skolemization},
except for the case of existential quantifiers which cause Liquid Haskell
to hang at the moment.\unsureF{Such a terrible ending for a great section. It is the SMT solver that seems to be hanging on some query.}


\subsection{Checking \tc{unifyEq}}
\label{checking-unifyEq}

We start introducing static checks by providing a refinement type signature to
the function \tc{unifyEq}, which encodes the scope check, the occurs check,
and the relationship of skolems present in the result and in the arguments.

\begin{verbatim}
unifyEq
  :: {t0:Term | consistentSkolemScopesTerm t0}
  -> {t1:Term |
          unionCommutes (scopesTerm t0) (scopesTerm t1)
       && consistentSkolemScopesTerm t1
     }
  -> [(v :: Var
      , { t:Term |
            isSubsetOfJust (freeVars t)
              (IntMap.lookup v
                (IntMap.union (scopesTerm t0) (scopesTerm t1)))
          && not (Set.member v (skolemSet t))
          && intMapIsSubsetOf (scopesTerm t)
               (IntMap.union (scopesTerm t0) (scopesTerm t1))
          && consistentSkolemScopesTerm t
        }
      )]
\end{verbatim}

The function \tc{scopesTerm} is only used in refinement types and it produces
a projection of the skolem applications in a given term. Instead of returning
full skolem applications, it only provides the skolem name and the domain of
the substitution.

\begin{verbatim}
scopesTerm :: Term -> IntMap (Set Int)
scopesTerm (V i) = IntMap.empty
scopesTerm (SA (i, s)) = IntMap.insert i (domain s) (scopesSubst s)
scopesTerm U = IntMap.empty
scopesTerm (L t) = scopesTerm t
scopesTerm (P t0 t1) = IntMap.union (scopesTerm t0) (scopesTerm t1)
\end{verbatim}

In this function we are using the data type \tc{IntMap}, also coming from the
package \tc{containers}. Liquid Haskell can link the calls in this function
with the array theory that is used to represent maps in the SMT solver.
The function \tc{scopesSubst} provides the skolems present in the range of
the substitution.

We define the predicate \tc{isSubsetOfJust} to say that the lookup succeeds
and that it yields a superset of the first argument.

\begin{verbatim}
isSubsetOfJust :: Ord a => Set a -> Maybe (Set a) -> Bool
isSubsetOfJust xs (Just ys) = Set.isSubsetOf xs ys
isSubsetOfJust xs Nothing = False
\end{verbatim}

We require the function \tc{IntMap.union} to be commutative when applied to
maps of scopes, despite of it being
defined as left-biased in the \tc{containers} package. This is because we
rely on the skolemization pass to ensure that, everywhere a
skolem occurs, the domain of the substitution is always the same.

\begin{verbatim}
unionCommutes :: Set a -> Set a -> Bool
unionCommutes s0 s1 = IntMap.union s0 s1 == IntMap.union s1 s0
\end{verbatim}

This allows us to define the predicate \tc{consistentSkolemScopesTerm},
which ensures that all occurrences of a skolem have the same domain in
their suspended substitutions in a given term.

\begin{verbatim}
consistentSkolemScopesTerm :: Term -> Bool
consistentSkolemScopesTerm (V _) = True
consistentSkolemScopesTerm SA{} = True
consistentSkolemScopesTerm U = True
consistentSkolemScopesTerm (L t) = consistentSkolemScopesTerm t
consistentSkolemScopesTerm (P t0 t1) =
    consistentSkolemScopesTerm t0 && consistentSkolemScopesTerm t1
    && unionCommutes (scopesTerm t0) (scopesTerm t1)
\end{verbatim}

The function \tc{intMapIsSubsetOf} is implemented by the authors in Liquid
Haskell, since it doesn't come from the package \tc{containers}. We say more
about it in Section~\ref{extending-liquid-haskell}. It returns
true if and only if all the key-value pairs of the first argument are contained
in the second.

When checking \tc{unifyEq}, the two first conjuncts of the return type can
be easily established since they match closely the guards in the first equation.
The third conjunct demands more calculation.

If we substitute \tc{t} by \tc{substitute s' t0} in the last conjunct, we get that we
need to prove

\begin{verbatim}
IntMap.isSubsetOf
  (scopesTerm (substitute s' t0)
  (IntMap.union (scopesTerm t0) (scopesTerm t1))
\end{verbatim}

Liquid Haskell does compute this on its own. Then we can use the fact that substitution
preserves the skolems returned by \tc{scopesTerm} to arrive at

\begin{verbatim}
IntMap.isSubsetOf
  (scopesTerm t0)
  (IntMap.union (scopesTerm t0) (scopesTerm t1))
\end{verbatim}

And this statement the SMT solver can prove on its own using the theory of arrays,
which can be used to implement maps. The only step that the user needs to spell out
is the property relating \tc{substitute} and \tc{scopesTerm}.

\begin{verbatim}
lemmaSubstituteScopesTerm
  :: s:Subst {ti:Term | isVar ti}
  -> t:Term
  -> { scopesTerm t = scopesTerm (substitute s t) }
\end{verbatim}

The range of the substitution \tc{s} is required to only contain variables, but
this is exactly what \tc{inverseSubst} produces!

\begin{verbatim}
isVar :: Term -> Bool
isVar (V _) = True
isVar _ = False

{-@ inverseSubst :: Subst Term -> {v:Subst {t:Term | isVar t} @-}
\end{verbatim}

Here is the proof of the lemma, which follows the recursive structure
of function \tc{substitute}.

\begin{verbatim}
lemmaSubstituteScopesTerm :: Subst Term -> Term -> ()
lemmaSubstituteScopesTerm s (SA (_, s1)) = lemmaComposeSubstDomain s1 s
lemmaSubstituteScopesTerm s U = ()
lemmaSubstituteScopesTerm s (L t) = lemmaSubstituteScopesTerm s t
lemmaSubstituteScopesTerm s (P t0 t1) =
    lemmaSubstituteScopesTerm s t0 `seq` lemmaSubstituteScopesTerm s t1
lemmaSubstituteScopesTerm s (V v) = case lookupSubst v s of
    { Nothing -> (); Just (V _) -> (); Just _ -> () }
\end{verbatim}

We cut the proof in the case of skolems with an assumption about the
skolems and domains of compositions of substitutions.
\begin{verbatim}
assume lemmaComposeSubstDomain
  :: s0:Subst Term -> s1:Subst {t:_ | isVar t}
  -> {   domain s0 == domain (composeSubst s0 s1)
      && scopesSubst s0 == scopesSubst (composeSubst s0 s1) }
\end{verbatim}

The last conjunct \tc{consistentSkolemScopesTerm t} of \tc{unifyEq} follows
from the refinement types of the inputs, and another lemma that relates
the skolem scopes with \tc{substitute}.
\begin{verbatim}
lemmaSubstituteConsistentScopes
  :: s:Subst {st:Term | consistentSkolemScopesTerm st && isVar st}
  -> {t:Term | consistentSkolemScopesTerm t}
  -> { consistentSkolemScopesTerm (substitute s t) }
\end{verbatim}
This lemma is provable in a similar way to \tc{lemmaSubstituteScopesTerm}.


\subsection{Checking \tc{unify}}
\label{checking-unify}

In the same way as in the previous section, we start checking the function \tc{unify}
by providing a refinement type signature. This is a rephrasing of the refinement
types of \tc{unifyEq} when the input is a formula instead of a pair of terms.

\begin{verbatim}
unify
  :: s:Set Int
  -> {f:Formula | consistentSkolemScopes f && existsCount = 0}
  -> [(v :: Var
      , { t:Term |
             isSubsetOfJust (freeVars t) (IntMap.lookup v (scopes f))
          && not (Set.member v (skolemSet t))
          && IntMap.isSubsetOf (scopesTerm t) (scopes f)
          && consistentSkolemScopes f
          && existsCount f = 0
        }
      )] / [formulaSize f]
\end{verbatim}

The recursion of unify is not structural since in the conjunction and implications
cases we are not feeding subformulas. Therefore we provide a termination
metric \tc{formulaSize} that counts the amount of connectives in a formula.
We have a function \tc{existsCount} that yields the amount of existential
quantifiers in a formula.
We also define a function \tc{scopes} analogous to \tc{scopesTerm} to obtain the skolems
of a formula.

\begin{verbatim}
scopes :: Formula -> IntMap Var (Set Int)
scopes (Forall _ f) = scopes f
scopes (Exists _ f) = scopes f
scopes (Conj f1 f2) = IntMap.union (scopes f1) (scopes f2)
scopes (Then (t0, t1) f2) =
  IntMap.union (scopesTerm t0) (IntMap.union (scopesTerm t1) (scopes f2))
scopes (Eq t0 t1) = IntMap.union (scopesTerm t0) (scopesTerm t1)
\end{verbatim}

We also define the predicate \tc{consistentSkolemScopes}, analogous to
\tc{consistentSkolemScopesTerm} which ensures that skolem scopes are
consistent in a formula.

Liquid Haskell can check mostly automatically the refinement type signature of
\tc{unify}. In the equations for quantifiers, unfolding definitions of
\tc{scopes} plus the refinement type of the recursive calls suffices.
In the equation of conjunction, the theory of arrays of the SMT solver
kicks in to establish the first conjunct of the refinement type:

\begin{verbatim}
unionCommutes (scopes f1) (scopes f2)
=>
(isSubsetOfJust (freeVars t) (IntMap.lookup v (scopes f1)) =>
  isSubsetOfJust
    (freeVars t)
    (IntMap.lookup v (IntMap.union (scopes f1) (scopes f2))))
&&
(isSubsetOfJust (freeVars t) (IntMap.lookup v (scopes f2)) =>
  isSubsetOfJust
    (freeVars t)
    (IntMap.lookup v (IntMap.union (scopes f1) (scopes f2))))
\end{verbatim}

The antecedent of the above goal is established by \tc{consistent\-Skolem\-Scopes}
in the refinement type of the input. The consequent relates the refinement types
of the recursive calls to the expected refinement type of the result, as Liquid
Haskell knows that \tc{IntMap.\allowbreak union (scopes f1) (scopes f2)} stands for
\tc{scopes (Conj f1 f2)}. An additional lemma is also needed to convince Liquid
Haskell that \tc{substituteSkolems} is going to preserve \tc{consistentSkolemScopes}.
This lemma relates the scopes of a substitution with the scopes in any map.
\begin{verbatim}
lemmaScopesListSubset
  :: m0:IntMap (Set Int)
  -> s:[(Var, {t:Term | intMapIsSubsetOf (scopesTerm t) m0})]
  -> { intMapIsSubsetOf (scopesList s) m0 }
\end{verbatim}
Here \tc{scopesList} is a function that collects the skolem scopes in a list of
pairs, and the lemma is instantiated with the scopes of the input formula.
\begin{verbatim}
unify s f@(Conj f1 f2) = do
    unifyF1 <- unify s f1
    let lemmaSubst = lemmaScopesListSubset (scopes f) unifyF1
    unifyF2 <- unify s (substituteSkolems (f2 ? lemmaSubst) unifyF1)
    return (unifyF1 ++ unifyF2)
\end{verbatim}
This lemma helps convince the SMT solver that the union of \tc{scopes f2}
and \tc{scopesList unifyF1} commutes, that is the scopes in the arguments of
\tc{substituteSkolems}, which is a necessary condition for ensuring that
\tc{consistentSkolemScopes} is preserved.

The second conjunct of the return refinement type of \tc{unify}
is accepted as it is established by the recursive calls and \tc{unifyEq}
as is. And the other equations in \tc{unify} are checked using similar reasoning,
all of it automatic except for a lemma similar to \tc{lemmaScopesListSubset} but
for the implication equation.


\subsection{Extending Liquid Haskell to support \tc{IntMap}}
\label{extending-liquid-haskell}

When we started our study, Liquid Haskell didn't support using the SMT solver
to reason with \tc{Map}s or \tc{IntMap}s.\footnote{Issue to support maps in the Liquid Haskell repository: \url{https://github.com/ucsd-progsys/liquidhaskell/issues/2534}}
In this section, we describe our modification to Liquid Haskell in order to address
this problem. While we can still use Liquid Haskell without these
changes, we would lose in automation. The tooling would require a lot more
lemmas from the user to check that the code handles the maps as expected.
All our modifications can be found in the files \tc{ifl25-\allowbreak liquidhaskell.patch}
and \tc{ifl25-\allowbreak liquid-\allowbreak fix\-point.patch}.\footnote{Patches for
liquidhaskell and liquid-fixpoint: \sourcefile{ifl25-liquidhaskell.patch} and
\sourcefile{ifl25-liquid-fixpoint.patch}}

We modified Liquid Haskell to leverage the SMT solver to reason with the type
\tc{IntMap (Set Int)}. These modifications can be easily adapted to
support other instantiations of \tc{Map a b} or \tc{IntMap b}, but a general
solution that can be reused for any instantiation of the type parameters still
needs to be implemented.

On the syntax front, Liquid Haskell allows to link a Haskell type with a particular
representation in the SMT solver.

\begin{verbatim}
{-@ embed IntMap * as IntMapSetInt_t @-}
\end{verbatim}

Here we are indicating that \tc{IntMap b} must be represented as \tc{IntMapSetInt\_t}
in the logic. \tc{IntMapSetInt\_t} is an alias for \tc{Array Int (Option (Set Int))}.
An array is an entity that associates keys with values, and which has an equality predicate,
and it is defined as one of the theories in SMT-LIB, the standard interface
to SMT solvers~\cite{BarFT-RR-25}.
The keys in this case are integers, and the values are either \tc{None} if the key
is not in the map, or \tc{Some s} if the key maps to a set \tc{s}. We name the data type
\tc{Option} to differentiated from Haskell's \tc{Maybe}, although both types are isomorphic.
We do not name it the same because the framework to connect to the SMT solver is
reused for other languages (e.g. \improvement{lehmann23}), and we prefer to keep
the implementation free of language specific details.
Here is the declaration of the \tc{Option} data type in SMT-LIB.

\begin{verbatim}
(declare-datatype Option (par (a) (None (Some (someVal a)))))
\end{verbatim}

We arranged for Liquid Haskell to include this declaration in the preamble of any
queries to the SMT solver. The types \tc{Array}, \tc{Int}, and \tc{Set} are already
known to the tooling.
It doesn't matter what type \tc{b} is instantiated to, the \tc{embed} annotation will
always set the same representation for \tc{IntMap b}, and this is a limitation that
would need to be addressed to support maps properly.

The array theory allows to describe how to retrieve the value associated with
a key, and how to update the value. On the Haskell front, we link these operations
to those of the \tc{IntMap b} type.

\begin{verbatim}
define IntMap.empty = (IntMapSetInt_default None)
define IntMap.insert x y m = IntMapSetInt_store m x (Some y)
define IntMap.lookup x m =
  if (isSome (IntMapSetInt_select m x)) then
    (GHC.Internal.Maybe.Just (someVal (IntMapSetInt_select m x)))
  else
    GHC.Internal.Maybe.Nothing
\end{verbatim}

The operations \tc{IntMapSetInt\_default}, \tc{IntMapSetInt\_store}, and \tc{IntMapSetInt\_select}
are aliases that we implemented in Liquid Haskell to call to the array operations.
In the case of \tc{lookup}, we translate the \tc{Option} type to Haskell's \tc{Maybe}.

The implementation of union, intersection,
difference, and subset checks for maps, however,
need operations beyond the standard interface, and not all SMT solvers can support
them. In our implementation we used the \tc{map} operation of the
Z3 SMT solver. The following snippet contains the implementation of
\tc{intMapIsSubsetOf} in SMT-LIB, and we also feed these declarations to the
SMT solver in a preamble to the queries.

\begin{verbatim}
; Similar to do {a0 <- oa0; a1 <- oa1; guard (a0 /= a1); pure a0}
(define-fun difference_strict_p2p
  ((oa0 (Option (Set Int)))
   (oa1 (Option (Set Int))))
  (Option (Set Int))
  (match oa0
    ((None None)
     ((Some a0) (match oa1
                  ((None oa0)
                   ((Some a1) (ite (= a0 a1) None oa0))))))))

; Similar to: empty == zipWith difference_strict_p2p xs ys
; where zipWith applies the function pointwise to the values in the
; arrays
(define-fun IntMapSetInt_isSubsetOf
  ((xs (Array Int (Option (Set Int))))
   (ys (Array Int (Option (Set Int)))))
  Bool
  (= ((as const (Array Int (Option (Set Int)))) None)
     ((_ map IntMapSetInt_difference_strict_p2p) xs ys)))
\end{verbatim}

Besides the limitation of the \tc{embed} annotation, another barrier for
proper support is that old versions of SMT-LIB require user defined
functions to have monomorphic types. This means, for instance, that
the type of \tc{IntMapSetInt\_isSubsetOf} cannot be generalized to work
on any \tc{IntMap}.

While newer versions of the standard allow
for polymorphic types, these still need to be implemented by SMT solvers.
Until the implementations catch up with the standard, feeding operations with
monomorphic types will require Liquid Haskell to be smart about generating
these operations with the appropriate types, instead of putting them in a
preamble once and for all queries.


\subsection{Other limitations of Liquid Haskell}
\label{limitations-of-liquid-haskell}

The source code of our unification example lists various defects to fix
in the user experience that required workarounds. A few of them seem to
be about ill-resolved names when translating Haskell identifiers to the
logic language, and there is one example of a function rejected by the
termination checker that should arguably be accepted.

In our code we have been using the simplest possible style of programming.
There are no GADTs, no type families, not even type classes, though
Liquid Haskell has some support for type classes~\cite{liu20}. At the moment,
pushing for more demanding programming patterns is likely to surface more
inconveniences. Aiming for the simplest style is, therefore, a constraint of
the current implementation, unless one is willing to contribute fixes or
look for the workarounds.

On the bright
side, none of the implementation issues that we have encountered in these
examples will require answering open research questions.
But for further insight on the challenges of using Liquid Haskell,
Gamboa et al.~\cite{gamboa25} report on a study that collects the voices
of its users.

\section{Evaluation of SMT solvers for interface checks}
\label{SMT-solvers-for-interface-checks}

As the case studies in this paper reinforce, SMT solvers can go a long way in
automating static checks. Insight from the user is necessary, however,
when the properties to check are not handled by any of the theories in the
solver.

When the property involves user defined recursive functions,
sometimes it still can be proved automatically if it is attached to the
refinement type signature of the function. This is the case of the refinement
types of functions \tc{substitute} and \tc{unification}, where the recursion
of the proof supports the inductive reasoning required to established the
property.

When the property cannot be expressed in the signature of a recursive function,
like the lemmas that have been presented, writing lemmas becomes necessary. The
inconvenience is two-fold. In the one hand, the lemma needs to be precisely
written and then demonstrated. And in the other hand, the user needs to figure
out the right set of parameters to apply it to at the sites where it is needed.

These inconveniences are alleviated by the fact that one can still use the
SMT solvers to write abbreviated demonstrations of the lemmas. Additionally,
it would be plausible that one can rely on additional mechanisms to help
discover the parameters to which they are applied. In the case of Liquid
Haskell, there is an implementation of automatic rewrite rules~\cite{grannan22}
that is meant to address the problem for lemmas about equalities.

It would be possible to ask the SMT solver to instantiate the lemma parameters
as needed by introducing assertions with universal quantification. For instance,
the universally quantified lemma \tc{lemma\-FreeVars\-Subst\-Union} follows.

\begin{verbatim}
(assert
  (forall
    ((s (Subst Term))
     (s1 (Set Int))
     (s2 (Set Int)))
    (freeVarsSubst (union s1 s2) s
       == union (freeVarsSubst s1 s) (freeVarsSubst s2 s))))
\end{verbatim}

When checking satisfiability of other assertions, the SMT solver
will try to use the universally quantified assertion. Unfortunately, the
behavior of the procedures to find instantiations for quantified variables are
not easy to predict. This is why Liquid Haskell refrains from doing it~\cite{vazou13}.

On the performance front, all of the SMT-LIB queries in the unification example run
in 6 seconds, 0.04 seconds for \tc{Subst2.hs}, and 0.03 seconds in \tc{Subst1.hs}.
That is sometimes faster than it takes to compile the modules with the GHC compiler.
Where things get slower is when measuring Liquid
Haskell, which spends several seconds checking the examples and interacting with the
SMT solver (37 seconds checking unification, 4 seconds checking \tc{Subst2.hs},
1.5 seconds checking \tc{Subst1.hs}). The authors deem that performance of Liquid Haskell
can be improved to approach that of the SMT solver queries, and probably further by
reducing the amount of queries.

Other than using an SMT solver in the fashion of Liquid Haskell, F*~\cite{swamy16},
Why3~\cite{filli13}, or Dafny~\cite{leino17},
the alternatives to implementing interface checks are either to encode the checks in
the type-checker, or to migrate to a dependently typed language for the sake of
static checking~\cite{haftmann10, breitner18, carr22}. Of these alternatives,
we feel like using the type-checker is among the most pragmatic. Maclaurin et al. make
a fine demonstration about the foil.

Perhaps one of the biggest compromises when encoding properties in the type-checker
is that one needs to narrow the expressible properties to a feasible set that allows
to write a supporting library. If we wanted to have static checks like those of the
unification example, ensuring that the return terms satisfy the scope check and the
occurs check would require new type encodings. Or in other words, new type indices
need to be conceived to relate the parameters of the function \tc{unify}.
$$\mathit{unify} :: \mathit{Formula}\ f_1 \ldots f_n -> [(\mathit{Var}\ v_1 \ldots v_m, \mathit{Term}\ t_1 \ldots t_r)]$$

Then there would be the effort of writing a library, and later on there would be the
effort of composing the encodings of different libraries when more than one such
is needed. Suppose we started with the static checks to avoid name captures as in
Section~\ref{capture-avoiding-substitution}, and we wanted to add the scopes checks
required to deal with unification variables. With refinement types we need to add
the corresponding conjuncts to the refinement types.

\begin{verbatim}
type ScopedFormula S = {f:Formula | isSubsetOf (freeVarsFormula f) S}
type ScopedTerm S = {t:Term | isSubsetOf (freeVars t) S}

substituteFormula
  :: scope:Set Int
  -> s:Subst (ScopedTerm scope)
  -> {f:ScopedFormula (domain s) |
           consistentSkolemScopes f
        && UnionCommutes (scopes f) (scopesSubst s)
     }
  -> {v:ScopedFormula scope |
          formulaSize f == formulaSize v
       && consistentSkolemScopes v
       && existsCount v = existsCount f
       && intMapIsSubsetOf (scopes v) (IntMap.union (scopes f) (scopesSubst s))
     }
\end{verbatim}
Besides the usual scope checks, we are checking that the size of the formula
is preserved, that the amount of existential binders is preserved, and that
the unification scopes in the output are those in the input formula and in
the range of the substitution. We also check that substitution preserves
the consistency of the unification scopes.

Less planning and setup seems necessary when composing refinement types, and
then we can hope SMT solvers to continue to check the same constraints
they were fed when the properties where checked in isolation.

The type-checker approach, however, is likely to produce error messages that
are easier to fix, provided that the user goal is feasible.
The user is guided into correcting the errors
by the types and the operations of the supporting library. With SMT solvers,
there is always the question of whether a goal is provable or not in the
theories at hand. Is there some additional lemma that is necessary about the user defined
functions? The user has to figure it out on her own. How are the assumptions
insufficient to prove the goal? The user has to compute it on her own too,
although it is plausible that counterexamples or better location information~\cite{webbers24}
can be proposed by the tooling when the integration matures.

As an example, let us consider the lemma \tc{lemmaSubstituteScopesTerm} discussed in
Section~\ref{checking-unifyEq}.
If we drop this lemma from the definition of \tc{unifyEq}, we get the following
error message, heavily edited for presentation.
\begin{verbatim}
tests/rapier/Unif.hs:570:7: error:
    Liquid Type Mismatch
    The inferred type
      VV : Term
    is not a subtype of the required type
      VV : {VV : Term |
               IntMapSetInt_isSubsetOf
                 (scopesTerm VV)
                 (IntMap.union (scopesTerm t0) (scopesTerm t1))}
    in the context
      t1 : {t1 : Term |
               consistentSkolemScopesTerm t1
            && UnionCommutes (scopesTerm t0) (scopesTerm t1)}

      s : {s : Subst Term |
             isSubsetOf (freeVars (substitute s' t1)) (domain s)}

      t0 : {t0 : Term |
               consistentSkolemScopesTerm t0 && t0 == SA (i, s)}

      s' : {s' : Subst Term |
               Just s' == inverseSubst (narrowForInvertibility (freeVars t1) s)
            && consistentSkolemScopesTerm (substitute s' t1)}

      i : {i : Int | not (Set.member i (skolemSet (substitute s' t1)))}
    Constraint id 3210
    |
570 |     = Just [(i, t')]
    |       ^^^^^^^^^^^^^^...
\end{verbatim}

We can get quickly that the goal is one of the conjuncts in the return
refinement type of \tc{unifyEq}.
But to get at the missing lemma, we need to calculate with the assumptions and the
code of the program. This error message doesn't say what is the term
with the given inferred type, but from the refinement type signature of
\tc{unifyEq} we can deduce that it is referring to \tc{t'}. Substituting \tc{VV}
by \tc{t'} in the predicate of the required type we get
\begin{verbatim}
IntMapSetInt_isSubsetOf
  (scopesTerm t')
  (IntMap.union (scopesTerm t0) (scopesTerm t1))
\end{verbatim}
Inspecting the code we see that \tc{t'} is the result of \tc{substitute s' t1}, so
we substitute again.
\begin{verbatim}
IntMapSetInt_isSubsetOf
  (scopesTerm (substitute s' t1))
  (IntMap.union (scopesTerm t0) (scopesTerm t1))
\end{verbatim}
And now is time to ponder whether this is true and, if so, why. It turns out that
if the function \tc{substitute} preserves the unification scopes of \tc{t1}, like
in
\begin{verbatim}
scopesTerm t1 = scopesTerm (substitute s' t1)
\end{verbatim}
then the SMT solver can establish that the goal is true. Unfortunately,
\tc{substitute} doesn't preserve unification scopes in general, but as we
noted when we presented the lemma earlier, it does preserve the scopes when
the range of the substitution \tc{s'} only contains terms which are variables.

When there are static check failures insight is often necessary to identify
a missing lemma or a missing precondition.
Recursive functions like \tc{skolemize} or \tc{unify} start with a core
set of conjuncts that is grown as static checks reveal the need of
stronger postconditions for the result of the recursive calls.


\section{Conclusions}
\label{conclusions}

We have presented two case studies to contrast the use of SMT solvers
with more traditional approaches based on type checking with strong types. In
our analysis, we tested the ability of SMT solvers to effectively automatize
the static checks otherwise left to the type system.

We found that refinement types enable a direct expression of properties,
particularly when the SMT solver supports the relevant theories. Reasoning
mechanisms are reused from the existing tooling, instead of encoding them
in the type checker. This makes easier both implementing static checks and
composing the properties coming from different sources.

However, integrating SMT solvers for static checks still presents some
challenges. One of them is maturing the existing integrations until they are
feasible to use in industrial setting. Another one is deriving useful
corrective actions from the error messages. And a last challenge is lowering
the checking overhead until it is close to the time required for queries to
the SMT solver alone.

The generality of the approach, and the simplicity with which it enables
composition of different static checks, are unique features that make it a strong
candidate to impact programming practice in the future.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}
\end{document}

% LocalWords:  invariants axiomatizes axiomatize integrations SMT subtyping

% Local Variables:
% ispell-local-dictionary: "american"
% End:
