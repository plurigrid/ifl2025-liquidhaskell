\documentclass[acmtog, anonymous, review]{acmart}
\usepackage[utf8]{inputenc}
\usepackage{fancyvrb}

%%%%%%%%%%%%%%%%% Editing marks %%%%%%%%%%%%%%%%%

  % TOGGLE ME to turn off all the commentary:
  \InputIfFileExists{no-editing-marks}{
    \def\noeditingmarks{}
  }

  \usepackage{xargs}
  \usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
  % ^^ Need for pgfsyspdfmark apparently?
  \ifx\noeditingmarks\undefined
      % Adapting to acmart's small margins
      \setlength{\marginparsep}{0.3em}
      \setlength{\marginparwidth}{1.4cm}

      \newcommandx{\unsure}[2][1=]{\todo[linecolor=orange,backgroundcolor=orange!25,bordercolor=orange,#1]{#2}}
      \newcommandx{\info}[2][1=]{\todo[linecolor=green,backgroundcolor=green!25,bordercolor=green,#1]{#2}}
      \newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
      \newcommandx{\inconsistent}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
      \newcommandx{\critical}[2][1=]{\todo[linecolor=purple,backgroundcolor=purple!25,bordercolor=purple,#1]{#2}}
      \newcommand{\improvement}[1]{\todo[linecolor=pink,backgroundcolor=pink!25,bordercolor=pink]{#1}}
      \newcommandx{\resolved}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}} % use this to mark a resolved question
    \else
      \renewcommand{\todo}{}
      \newcommandx{\unsure}[2][1=]{{}}
      \newcommandx{\info}[2][1=]{{}}
      \newcommandx{\change}[2][1=]{{}}
      \newcommandx{\inconsistent}[2][1=]{{}}
      \newcommandx{\critical}[2]{{}}
      \newcommand{\improvement}[1]{{}}
      \newcommandx{\resolved}[2][1=]{{}}

  \fi

%%%%%%%%%%%%%%%%% /Editing marks %%%%%%%%%%%%%%%%%

\title{Interface design with SMT solvers: A study}

\author{undisclosed author/s}
\author{Facundo Dom√≠nguez}
\affiliation{
     \institution{Tweag}
     \country{Uruguay}
}
\email{facundo.dominguez@tweag.io}
\author{Arnaud Spiwack}
\affiliation{
     \institution{Tweag}
     \country{France}
}
\email{arnaud.spiwack@tweag.io}
\keywords{refinement types, SMT solvers, static analysis, formal verification}
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003752.10010124.10010138.10010142</concept_id>
       <concept_desc>Theory of computation~Program verification</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10010124.10010138.10010140</concept_id>
       <concept_desc>Theory of computation~Program specifications</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Theory of computation~Program verification}
\ccsdesc[500]{Theory of computation~Program specifications}

\newcommand{\tc}[1]{{\small\texttt{#1}}}
\newcommand{\codeblocksize}{\fontsize{6.5}{9}\selectfont}
\newcommand{\sourcefile}[1]{\anon[#1 (in accompanying zip file)]{{\scriptsize\url{https://github.com/facundominguez/liquidhaskell/blob/fd/rapier/tests/rapier/#1}}}}
\RecustomVerbatimEnvironment{verbatim}{Verbatim}{
    fontsize=\codeblocksize,
}

\begin{document}
\begin{abstract}
    This paper explores the use of Satisfiability Modulo Theories (SMT) solvers,
    specifically through Liquid Haskell, to enhance static checks of
    programming language interfaces. Traditional approaches in strongly typed
    languages balance type richness with interface usability. We present a
    third alternative: leveraging SMT solvers via refinement types to offload
    static checks from the type checker. Our study includes a comparative
    analysis of capture-avoiding substitution, demonstrating the advantages of
    Liquid Haskell over type-checker-based methods. Furthermore, we investigate
    the application of SMT solvers to unification, a more complex scenario,
    highlighting both the capabilities and current limitations of this
    approach. We showcase modifications to Liquid Haskell to support these
    advanced checks, demonstrating technical feasibility. The paper also
    argues for the broad applicability of SMT solvers in ensuring various
    program properties, suggesting that their integration can significantly
    improve both the power and convenience of static checks in programming.
\end{abstract}
\maketitle

\section{Introduction}

Application Programming Interfaces (APIs) in programming languages are
typically described with the types of their operations alongside
supplementary documentation.
In a strongly typed language, the author of an interface can aim to enrich the
types to represent most of the constraints and relationships between the
operations, or she could decide to keep the types as simple as possible.

Rich types enable the type checker to detect interface misuse,
thus preventing execution failures or
incorrect results. However, this richness often increases interface complexity,
potentially making it cumbersome to use. Developers must therefore strike a
balance.

The options are not just to lean or not to lean on the type checker, though. In
this paper we analyze a couple of use cases in the Haskell programming language
from the perspective of a third alternative. We implement the static checks of
the interfaces with automated theorem provers, more specifically, SMT solvers.
And we connect SMT solvers with Haskell by using refinement types as implemented
in the Liquid Haskell verification tool~\cite{vazou14b}.

While SMT solvers have always been intended to support programming~\cite{barnett05, demoura08}, it has
been less discussed how their integration through refinement types influences
interface design. Therefore, our first contribution is a study of
capture-avoiding substitution with safety checks implemented with Liquid Haskell,
where we compare with an earlier attempt based on the Haskell type checker, dubbed
\textit{the foil}~\cite{maclaurin23}
(Section~\ref{capture-avoiding-substitution}). Later on, we implement safety checks
in an implementation of unification (Section~\ref{unification}), a more demanding
example where extending earlier approaches would be some challenge. Our
attempt with unification is only partially successful since we had to
modify the Liquid Haskell implementation to support it. These modifications
constitute our third contribution, and demonstrate the technical feasibility
of the approach. Lastly, we offer a discussion
of the limitations of both the Liquid Haskell implementation (Section~\ref{limitations-of-liquid-haskell}) and the
general approach of integrating SMT solvers via refinement
types (Section~\ref{SMT-solvers-for-interface-checks}).

Over the years SMT solvers have been used effectively to statically check pointer
arithmetic, data structure invariants~\cite{vazou14}, memory safety, side-channel
safety in cryptographic algorithms~\cite{zinzin17},
safe parsing of binary input~\cite{swamy22}, data access policies in web applications~\cite{lehmann21},
commutativity of operations on replicated data types~\cite{liu20}, causal ordering in
broadcast protocols~\cite{redmond23}, and more. There is no question of whether SMT solvers are
helpful but whether they can be integrated conveniently in everyday
programming, or more specifically in this article, in offloading safety static
checks from the type checker.
We anticipate that the integration of SMT solvers will make programming more
pleasant and static checks more powerful in these and other scenarios to come.


\section{Capture-avoiding substitutions}
\label{capture-avoiding-substitution}

Name capture is recognized as one of the most common mistakes when writing compilers.
A way to make it happen is when substituting under binders like in
$(\lambda x. y)[y:=t]$. The result of the substitution is $\lambda x. t$.
Thus $(\lambda x. y)[y:=z]$ is $\lambda x. z$, and after the substitution
we still have a function that returns a constant value. But if we substitute
as in $(\lambda z. y)[y:=z]$, we obtain $\lambda z. z$, the identity function!
This change of meaning is often unwanted and is caused by the binder capturing
free variables in $t$.

The GHC Haskell compiler uses an approach to avoid name capture called
\textit{the rapier}~\cite{peytonjones02secrets}. It requires the
implementation of substitutions to carry an additional \textit{scope} set containing all the
variables that appear free in the result of the substitution. This set is
used both to decide what to rename a binder to, in order to avoid name capture,
and it is also used to skip renaming a binder if it wouldn't capture any free
variables. Figure~\ref{rapier-style-substitution} shows an implementation of the
technique on the untyped lambda calculus.

\begin{figure}
\begin{verbatim}
data Exp = Var Int | App Exp Exp | Lam Int Exp

substitute :: Set Int -> Subst Exp -> Exp -> Exp
substitute scope s e0 = case e0 of
  Var i -> case lookupSubst i s of Nothing -> e0; Just e -> e
  App e0 e1 -> App (substitute scope s e0) (substitute scope s e1)
  Lam i e
    | member i scope,
      let j = freshVar scope ->
        Lam j $ substitute (insert j scope) (extendSubst s i (Var j)) e
    | otherwise ->
        Lam i $ substitute (insert i scope) (extendSubst s i (Var i)) e

freshVar :: Set Int -> Int
freshVar s = case lookupMax s of Nothing -> 0; Just i -> i + 1
\end{verbatim}
\caption{Rapier style substitution}
\Description{Haskell implementation of substitution for untyped lambda terms using the rapier}
\label{rapier-style-substitution}
\end{figure}

\subsection{The rapier with stronger types}
\label{the-rapier-with-stronger-types}

Maclaurin et al.~\cite{maclaurin23} go over the merits and difficulties of the rapier. In
particular, a few requirements need to be respected when implementing it, or
software faults ensue. Here is a recollection of the requirements in question:
\begin{enumerate}
\item Membership to the scope set needs to be tested for every binder encountered
      during the substitution traversal, and the binders need to be renamed if
      they are in the set.
\item The scope set needs to be constructed correctly before starting a substitution.
      It should contain all of the variables in the result of the substitution,
      and it can also be a superset of those. Since we don't have the result of
      the substitution yet, we turn to specify it in terms of the inputs as well.
      \begin{enumerate}
      \item The scope set needs to include all the variables free in the input
            lambda expression. Otherwise, renaming a variable could accidentally
            capture a free variable. The only exception to this rule are the
            variables that also happen to be in the domain of the substitution
            (binders that capture them don't need to be renamed since the substitution
            will replace occurrences of those free variables).
      \item The scope set needs to include all the variables free in the range
            of the substitution.
      \end{enumerate}
\item Binders need to be added to the scope set whenever they are encountered,
      so further attempts to rename other binders don't capture them.
\item When renaming a binder, the new name must be guaranteed to not belong to
      the scope set.
\item When renaming a binder, the occurrences of the old bound variable need to be
      substituted with the new name.
\item The binders need to be removed from the domain of the substitution when
      they are not in the scope set, otherwise the substitution will happily
      replace occurrences of those bound variables! An alternative we use in
      Figure~\ref{rapier-style-substitution} is to redefine the substitution to
      map the variable of the binder to itself.
\end{enumerate}

Maclaurin et al. propose to use the type checker to ensure most of these
requirements, thus reducing the chance of programmer mistakes, in an approach they
name \text{the foil}. They
propose a library with types \tc{Scope n}, \tc{Name n}, and
\tc{Name\-Binder n l}. A value of type \tc{Scope n} is a set of names, where
the type index \tc{n} identifies the set. A value of type \tc{Name n} is a name that
belongs to the set with type \tc{Scope n}. A value of type \tc{NameBinder n l} is
a name in the set with type \tc{Scope l} which results from adding such single
name to the set with type \tc{Scope n}. These types are meant to be used in
the abstract syntax tree of a client application. For instance

\begin{quotation}
\begin{verbatim}
data Exp n = Var (Name n)
           | App (Exp n) (Exp n)
           | forall l. Lam (NameBinder n l) (Exp l)
\end{verbatim}
\end{quotation}

Then the operations and type checking on the new types will guide the user into
respecting much of the scope requirements when implementing substitution.

\begin{verbatim}
substitute :: Distinct o => Scope o -> Subst Expr i o -> Expr i -> Expr o
\end{verbatim}

This type signature says that no names shadow each other in the scope set \tc{o}.
It also says that the substitution will take a expression with free variables in
a scope set \tc{i} and produce an expression with free variables in a scope set
\tc{o}.

There
are mechanisms to check that a scope set is a subset of another, to assert that no
name shadows another one in a given scope set, to reason that expressions
with free variables in one scope (\tc{Exp n}) can be coerced to expressions with
free variables in a superset (\tc{Exp l}), and to introduce scope sets that extend
others with freshly created names. They also provide an implementation of maps of
variables to expressions, that is the substitutions to apply, with an interface
that uses the new types as well. There is for instance the following function to
produce fresh variables:

\begin{verbatim}
withRefreshed
  :: Distinct o
  => Scope o
  -> Name i
  -> (forall (o' :: S). DExt o o' => NameBinder o o' -> r)
  -> r
\end{verbatim}

Using the constraint \tc{DExt}, this type signature says that scope set \tc{o'}
extends the scope set \tc{o} with the given \tc{NameBinder o o'}. This binder
may have the same name as the provided \tc{Name i} if it was not present in
\tc{o}, otherwise it will be a fresh name. As another example, the following
function always produces a fresh name.

\begin{verbatim}
withFresh
  :: Distinct n
  => Scope n
  -> (forall l . DExt n l => NameBinder n l -> r )
  -> r
\end{verbatim}

With these measures, the foil is able to address the above requirements except the
last one, which must be handled carefully in the unsafe part of their API. This
is not discussed in their publication, but it can be handled in their \tc{addRename}
function.\footnote{Compare the function \tc{addRename} in the publication with this implementation of it:
{\scriptsize\url{https://hackage.haskell.org/package/free-foil-0.2.0/docs/src/Control.Monad.Foil.Internal.html\#addRename}}}


\subsection{The rapier with refinement types}
\label{the-rapier-with-refinement-types}

We set now to improve upon the rapier with Liquid Haskell. The code presented in
this section is available as
\tc{Subst4.hs}\footnote{The simplest approach with Liquid Haskell: \sourcefile{Subst4.hs}}
in our repository. Liquid Haskell is a
verification tool for Haskell programs. When given a program, the tool will
check statically that the functions in the program respect formal specifications
provided by the programmer. Liquid Haskell doesn't implement all the reasoning
directly. Instead, it will generate logical assertions or constraints from the
abstract syntax tree of the program, that it will then feed to an SMT solver.

Specifications, in turn, are given in a form of dependent types
known as refinement types. A value has a refinement type $\{v:b\ |\ p\ v\}$ when
it has a base type $b$, and it also satisfies predicate $p$. In Liquid Haskell,
$p$ is a function returning a boolean value. Here's an example for the
\tc{freshVar} function.

\begin{verbatim}
import Data.Set
{-@ assume freshVar :: s:Set Int -> {v:Int | not (member v s)} @-}
\end{verbatim}

Liquid Haskell reads refinement type signatures and other annotations from
inside special Haskell comments
\tc{\{-@ \ldots\ @-\}}. We will skip them in our snippets when it is clear
that we are presenting annotations.
The predicates in the refinement types are in a language of expressions
referred to as the logic language. For the sake of this paper, we can
regard it as a subset of Haskell. The predicates are assembled from
functions in the Haskell program and functions that might be available
only in the logic.
A function like \tc{member}, which comes from the module \tc{Data.Set}
in the \tc{containers} package, is linked by Liquid Haskell to the set
theory of the SMT solver.

Refinement type signatures starting with the \tc{assume} keyword declare that the
corresponding Haskell function should honor the signature, but it isn't
checked. When \tc{freshVar} is called in other functions, Liquid Haskell
will assume that the returned variable is fresh whatever the implementation
of \tc{freshVar} does. In contrast, Liquid Haskell is going to check that
the rapier implementation of Figure~\ref{rapier-style-substitution} meets the
following refinement type signature of \tc{substitute}.

\begin{verbatim}
{-@
type ScopedExp S = {e:Exp | isSubsetOf (freeVars e) S}

substitute
  :: scope:Set Int
  -> s:Subst (ScopedExp scope)
  -> ScopedExp (domain s)
  -> ScopedExp scope
@-}
substitute :: Set Int -> Subst Exp -> Exp -> Exp
\end{verbatim}

We first define a type alias \tc{ScopeExp S}, that is the type of all
expressions whose free variables are in the set \tc{S}.\footnote{In type aliases,
Liquid Haskell expects parameter names to start with an uppercase letter.}
Then we provide a type signature for the function \tc{substitute} using
refinement types.

Functions like \tc{isSubsetOf} and \tc{difference} come from the \tc{Data.\allowbreak Set}
module. The function \tc{freeVars} is in the same module as \tc{subs\-ti\-tute},
and collects the free variables of an expression. We note that this function
is only used in refinement type signatures, and in particular, it is not evaluated
when calling to \tc{substitute}.

\begin{verbatim}
freeVars :: Exp -> Set Int
freeVars e = case e of
  Var i -> singleton i
  App e1 e2 -> union (freeVars e1) (freeVars e2)
  Lam i e -> difference (freeVars e) (singleton i)
\end{verbatim}

Lastly, there is the function \tc{domain} defined solely within the logic
language.

\begin{verbatim}
{-@ measure domain :: Subst e -> Set Int @-}
\end{verbatim}

This is the way in which uninterpreted functions are declared. The function
\tc{domain} stands for the set of variables in the domain of a substitution.
Liquid Haskell doesn't know anything more about it than its type signature,
but the user can enrich such knowledge within the refinement type signatures
of the substitution operations that manipulate the domain.

\begin{verbatim}
assume lookupSubst
  :: k:Int
  -> xs:Subst e
  -> {m:Maybe e | isJust m == member k (domain xs) }

assume extendSubst
  :: s:Subst a
  -> i:Int
  -> a
  -> {v:_ | union (domain s) (singleton i) = domain v }
\end{verbatim}

Now, for instance, whenever Liquid Haskell encounters an application
of the function \tc{lookupSubst}, it will assume that the key is in the domain
of the substitution if the lookup succeeds.

Our refinement type signature of \tc{substitute} follows the type signature of
Maclaurin et al. to the letter. With these annotations, Liquid Haskell can ensure that the
implementation of substitution in Figure~\ref{rapier-style-substitution} meets
all of the requirements in Section~\ref{the-rapier-with-stronger-types}, except
for the first requirement, which we discuss further in the next subsection.

Liquid Haskell ensures the last requirement because the
refinement types of the recursive call demands the free variables of the lambda
body to be in the domain of the substitution. Since these free variables might
contain the binder variable, the substitution is not accepted without extending
it first.

\subsection{Ensuring the scope set is checked}
\label{ensuring-the-scope-set-is-checked}

Checking that the scope set is actually used, and therefore that binders to rename
are not forgotten, admits at least two approaches. In both cases we will prevent
the user from making a recursive call to \tc{substitute} without checking first
if the binder needs renaming.

The first approach prevents the user from inserting a name into a scope if that
name is in the scope already. In such case, a fresh name has to be inserted instead.
And it is not possible to skip updating the scope since the other enforced checks
demand it. This is the new function that we offer to insert elements into a scope
set.

\begin{verbatim}
newtype Scope = UnsafeScope (Set Int)
{-@
withRefreshed :: s:Scope -> i:Int
  -> {p:(Scope, Int) |
       not (member (snd p) s) && fst p == union s (singleton (snd p))}
@-}
withRefreshed :: Scope -> Int -> (Scope, Int)
withRefreshed (UnsafeScope s) i
  | Set.member i s = let j = freshVar s in (UnsafeScope (insert j s), j)
  | otherwise = (UnsafeScope (insert i s), i)
\end{verbatim}

The refinement type signature of the function captures the fact that the returned
name is not in the input set \tc{s}, and that the returned set is an
extension of the input. We also need to wrap our sets of names into a
\tc{newtype} in order to hide the \tc{insert} operation from the programmer,
otherwise she could accidentally omit using \tc{withRefreshed} to create
new scope sets. This solution is available in the file
\tc{Subst5.hs}\footnote{A solution that addresses all requirements: \sourcefile{Subst5.hs}}
in our repository.

The second approach, avoid introducing \tc{withRefreshed} and modifying the
types in the program by providing a more stringent refinement type for
\tc{substitute}.

\begin{verbatim}
substitute
  :: scope:Set Int
  -> s:Subst (ScopedExp scope)
  -> ei:ScopedExp (domain s)
  -> {v:Exp | freeVars v == freeVarsSubst (freeVars ei) s}
\end{verbatim}

In this signature we are spelling exactly what the expected free variables in the result are.
We use a function \tc{freeVarsSubst} such that
\tc{freeVarsSubst (freeVars e) s} computes the free variables in the range of the
substitution \tc{s} that is actually used when applying it
to the expression \tc{e}. We provide an example representation for substitutions and
a schematic presentation of \tc{freeVarsSubst}, but in our implementation we
are careful to keep the checks agnostic on the actual representation of
substitutions.

\begin{verbatim}
type Subst e = [(Int, e)]
freeVarsSubst :: Set Int -> Subst Exp -> Set Int
freeVarsSubst used [] = empty
freeVarsSubst used ((i, e) : xs) =
  | member i used = -- only take the first occurrence of i
      union (freeVars e) (freeVarsSubst (difference used (singleton i)) xs)
  | otherwise = freeVarsSubst used xs
\end{verbatim}

Unless we rename all the binders unconditionally, it is no longer
possible to ignore the scope set when going under binders since the calculation
of free variables doesn't add up:
If the name of the binder is in the free variables of the range of the substitution,
it may show up in the free variables of the result, but leaving it unrenamed would
cause the call to the function \tc{freeVars} in the expected return refinement type
to disagree.

Unfortunately, this refinement type signature is more laborious to check, as
\tc{free\-Vars\-Subst} requires roughly one lemma per case of the \tc{subs\-ti\-tute}
function.

\begin{verbatim}
lemmaFreeVarsSubstSing :: i:_ -> s:_
  -> { freeVarsSubst (singleton i) s == fromMaybe empty (lookupSubst i s) }

lemmaFreeVarsSubstUnion :: s1:_ -> s2:_ -> s:_
  -> { freeVarsSubst (union s1 s2) s
         == union (freeVarsSubst s1 s) (freeVarsSubst s2 s) }

lemmaFreeVarsSubstExtend
  :: scope:_ -> used:_
  -> i:_ -> {e:_ | Data.Set.null (intersection (freeVars e) scope)}
  -> s:Subst (ScopedExp scope)
  -> { freeVarsSubst (difference used (singleton i)) s ==
       difference (freeVarsSubst used (extendSubst s i e)) (freeVars e)
     }
\end{verbatim}

Each lemma requires writing a recursive function for Liquid Haskell to
check it, which is additional effort. Here's the proof for
\tc{lemma\_free\-Vars\-Subst\_union}.

\begin{verbatim}
lemmaFreeVarsSubstUnion :: Set Int -> Set Int -> Subst Exp -> ()
lemmaFreeVarsSubstUnion _ _ [] = ()
lemmaFreeVarsSubstUnion s1 s2 ((i, _) : xs) =
  lemmaFreeVarsSubstUnion
    (difference s1 (singleton i)) (difference s2 (singleton i)) xs
\end{verbatim}

The recursive function follows the structure of an inductive proof,
with much of the folding, unfolding, and set properties applied
automatically. And this is similar for the proofs of the other lemmas.
Then the lemmas need to be applied in the cases of \tc{substitute}.

\begin{verbatim}
substitute scope s e0 = case e0 of
  Var i -> case lookupSubst i s of
    Nothing -> e0
    Just e -> e ? lemmaFreeVarsSubstSing i s
  App e0 e1 ->
    App (substitute scope s e0) (substitute scope s e1)
      ? lemmaFreeVarsSubstUnion (freeVars e0) (freeVars e1) s
  Lam i e
    | member i scope,
      let j = freshVar scope ->
        Lam j $ substitute (insert j scope) (extendSubst s i (Var j)) e
          ? lemmaFreeVarsSubstExtend scope (freeVars e) i (Var j) s
    | otherwise ->
        Lam i $ substitute (insert i scope) (extendSubst s i (Var i)) e
          ? lemmaFreeVarsSubstExtend scope (freeVars e) i (Var i) s
\end{verbatim}

The operator \tc{?} is an alias for function \tc{const = \textbackslash x \_ -> x} and
brings the lemma into consideration of Liquid Haskell when checking the
first argument without evaluating the recursive function that stands for
the lemma proof. This solution is available in the file
\tc{Subst3.hs}\footnote{A solution that addresses all requirements without changing types in the program: \sourcefile{Subst3.hs}}
in our repository.


\subsection{Comparison}

Liquid Haskell ensures most requirements with little assistance
because it is delegating much of the work to an underlying SMT solver.
SMT solvers are tools that decide whether (usually first order) logic formulas are
satisfiable and provide dedicated mechanisms to reason about various theories
(sets, strings, arrays, integers, reals, etc).

In the case of capture-avoiding substitution, multiple queries that
Liquid Haskell gives to the SMT solver involve reasoning on sets, thus
making effective use of its capabilities. Moreover, the expression of
relationships between arguments and result is fairly natural with
refinement types. When there are lemmas to prove, despite of being
additional effort to write, they still have proofs that don't require
a lot of creativity.

On the other hand, an approach like the foil does need the author to
think carefully about how to encode the various static checks with the
type checker, a non trivial supporting library needs to be written,
and the effort might need further iterations when accounting for
additional properties.
After our next case study, we will have more to say on the experience
of implementing interface checks in Section~\ref{SMT-solvers-for-interface-checks}.


\section{Unification}
\label{unification}

In this section we look now at another example where we can put the theories
of SMT solvers to work for us. This is conditional unification of a form of
hereditary Harrop formulas. The source code of this section can be found in
\sourcefile{Unif2.hs}.

Here, variables are again represented as integers, and we also have a form of
skolem function application $f(t_0,\ldots,t_n)$ represented as a pair
$(f, [x_0:=t_0,\ldots,x_n:=t_n])$, where $x_0 \ldots x_n$ are the only free
variables allowed in the solutions of $f$.

\begin{verbatim}
type Var = Int
type SkolemApp = (Var, Subst Term)
\end{verbatim}

The purpose of the skolem $f(t_0,\ldots,t_n)$ is to replace existential variables
in a formula like $\forall x. \exists z. z = x$ to get $\forall x. f_z(x) = x$, which
in our representation will be $\forall x. (f_z, [x:=x]) = x$.
The purpose of unification would be to find a value of $f_z$ that only has the variable
$x$ free, and that makes the formula true.

\begin{verbatim}
data Term
  = V Var | SA SkolemApp | U | L Term | P Term Term deriving

data Formula
  = Eq Term Term               -- equality
  | Conj Formula Formula       -- conjunctions
  | Then (Term, Term) Formula  -- a = b => f
  | Exists Var Formula         -- existential quantification
  | Forall Var Formula         -- universal quantification
\end{verbatim}

Our term language allows for variables, skolem applications, and some artificial
data constructors (i.e. injective functions). The language of formulas has
equality, conjunction, existential and universal quantification, and it also
has a form of implication that only allows for equalities in the antecedent.
The conception is driven by the simplest language that still would allow to
express something of practical interest like constraints of generalized
algebraic data types (GADTs)~\cite{schrijvers09}.

Our unification algorithm is then expressed in Figure~\ref{conditional-unification}.
When unification fails, we return an incomplete list of solutions, that is one that
doesn't provide solutions for all the skolems in a formula.
There are a few preparation passes on unification formulas that we have elided since
they aren't essential to the discussion in this section.
Existential variables would be replaced with skolem applications, equalities of
data constructors like $P a b = P c d \Rightarrow f$ are split to
$a = c \land b = d \Rightarrow f$, formulas are normalized to prenex form, variables
are renamed to avoid name captures, etc. We have functions \tc{substitute} and
\tc{substituteSkolems} to apply substitutions in terms and substitutions of skolems
in formulas. We have a function \tc{skolemSet} to collect the skolems of a
term. And we have a function \tc{fromListSubst} to construct a substitution from
a list of pairs \tc{[(Var, Term)]}.

\begin{figure}
\begin{verbatim}
unify :: Formula -> [(Var, Term)]
unify (Forall v f) = unify f
unify (Exists v f) = unify f
unify (Conj f1 f2) = unify f1 ++ unify f2
unify (Then (t0, t1) f2) =
  let unifsT1 = unifyEq t0 t1
      unifsT1Subst = fromListSubst unifsT1
   in unifsT1 ++ unify (substituteSkolems unifsT1Subst f2)
unify (Eq t0 t1) = unifyEq t0 t1

unifyEq :: Term -> Term -> [(Var, Term)]
unifyEq t0 t1@(SA (i, s))
  | Just s' <- inverseSubst $ narrowForInvertibility (freeVars t0) s
  , let t' = substitute s' t0
  , not (Set.member i (skolemSet t'))
  , Set.isSubsetOf (freeVars t') (domain s)
  = [(i, t')]
unifyEq t0@(SA _) t1 = unifyEq t1 t0
unifyEq _ _ = []

-- | @narrowForInvertibility vs s@ removes pairs from @s@ if the
-- range is not a variable, or if the range is not a member of @vs@.
narrowForInvertibility :: Set Var -> Subst Term -> Subst Term
narrowForInvertibility vs (Subst xs) =
  Subst [(i, V j) | (i, V j) <- xs, Set.member j vs]

inverseSubst :: Subst Term -> Maybe (Subst Term)
inverseSubst (Subst xs) = fmap Subst (go xs)
  where
    go [] = Just []
    go ((i, V j) : xs) = fmap ((j, V i) :) (go xs)
    go _ = Nothing
\end{verbatim}
\caption{Conditional unification}
\Description{Haskell implementation of condition unification}
\label{conditional-unification}
\end{figure}

The function \tc{unifyEq} defines what a good solution should be.
One of the conditions is that whatever term \tc{t'} is proposed
as solution for a skolem \tc{i}, it needs to have as free variables only those in the
domain of the substitution defining the skolem application
(\textit{scope check}). Another
condition is that the skolem \tc{i} should not occur in the solution
\tc{t'} (\textit{occurs check}). And since we are inverting a substitution to find
\tc{t'}, we might not find solutions if we cannot invert the
substitution. This implementation only inverts substitutions where
variables are mapped to variables. That is, we solve $(f, [z:=x]) = L(L(x))$
to get the solution $(f, L(L(z)))$ but we do not try solving $(f, [z:=L(x)]) = L(L(x)))$.

\subsection{Checking \tc{unifyEq}}

We start introducing static checks by providing a refinement type signature to
the function \tc{unifyEq}, which encodes the scope check, the occurs check,
and the relationship of skolems present in the result and in the arguments.

\begin{verbatim}
unifyEq
  :: t0:Term
  -> {t1:Term | unionCommutes (scopesTerm t0) (scopesTerm t1)}
  -> [(v :: Var
      , { t:Term |
            isSubsetOfJust (freeVars t)
              (IntMap.lookup v
                (IntMap.union (scopesTerm t0) (scopesTerm t1)))
          && not (Set.member v (skolemSet t))
          && intMapIsSubsetOf (scopesTerm t)
               (IntMap.union (scopesTerm t0) (scopesTerm t1))
        }
      )] / [terminationUnifyEq t0 t1]
\end{verbatim}

The function \tc{scopesTerm} is only used in refinement types and it produces
a projection of the skolem applications in a given term. Instead of returning
full skolem applications, it only provides the skolem name and the domain of
the substitution.

\begin{verbatim}
scopesTerm :: Term -> IntMap (Set Int)
scopesTerm (V i) = IntMap.empty
scopesTerm (SA (i, s)) = IntMap.insert i (domain s) (scopesSubst s)
scopesTerm U = IntMap.empty
scopesTerm (L t) = scopesTerm t
scopesTerm (P t0 t1) = IntMap.union (scopesTerm t0) (scopesTerm t1)
\end{verbatim}

In this function we are using the data type \tc{IntMap}, also coming from the
package \tc{containers}. Liquid Haskell can link the calls in this function
with the array theory that is used to represent maps in the SMT solver.
The function \tc{scopesSubst} provides the skolems present in the range of
the substitution.

We define the predicate \tc{isSubsetOfJust} to say that the lookup succeeds
and that it yields a superset of the first argument.

\begin{verbatim}
isSubsetOfJust :: Ord a => Set a -> Maybe (Set a) -> Bool
isSubsetOfJust xs (Just ys) = Set.isSubsetOf xs ys
isSubsetOfJust xs Nothing = False
\end{verbatim}

We assume the function \tc{IntMap.union} to be commutative despite of it being
defined as left-biased in the \tc{containers} package. This is because we
rely on the preceding passes of unification to ensure that everywhere a
skolem occurs, the domain of the substitution is always the same.

\begin{verbatim}
unionCommutes :: Set a -> Set a -> Bool
unionCommutes s0 s1 = IntMap.union s0 s1 == IntMap.union s1 s0
\end{verbatim}

The function \tc{intMapIsSubsetOf} is implemented by the authors in Liquid
Haskell, since it doesn't come from the package \tc{containers}. It returns
true if and only if all the key-value pairs of the first argument are contained
in the second.

The function \tc{terminationUnifyEq} is a metric that we provide so Liquid
Haskell can check that \tc{unifyEq} terminates. When the recursion is
structural, termination can be proved without extra considerations, but in
this case we are doing a recursive call that swaps the order of the arguments.
The metric that we provide must be greater or equal to 0 and must decrease on
each recursive call.

\begin{verbatim}
{-@ terminationUnifyEq :: Term -> Term -> {v:Int | v >= 0} @-}
terminationUnifyEq :: Term -> Term -> Int
terminationUnifyEq (SA _) _ = 1
terminationUnifyEq _ (SA _) = 0
terminationUnifyEq _ _ = 0
\end{verbatim}

When checking \tc{unifyEq}, the two first conjuncts of the return type can
be easily established since they match exactly the guards in the first equation.
The last conjunct demands more calculation.

If we substitute \tc{t} by \tc{substitute s'} in the last conjunct, we get that we
need to prove

\begin{verbatim}
IntMap.isSubsetOf
  (scopesTerm (substitute s' t0)
  (IntMap.union (scopesTerm t0) (scopesTerm t1))
\end{verbatim}

Liquid Haskell does compute this on its own. Then we can use the fact that substitution
preserves the skolems returned by \tc{scopesTerm} to arrive at

\begin{verbatim}
IntMap.isSubsetOf
  (scopesTerm t0)
  (IntMap.union (scopesTerm t0) (scopesTerm t1))
\end{verbatim}

And this statement the SMT solver can prove on its own using the theory of arrays,
which can be used to implement maps. The only step that the user needs to spell out
is the property relating \tc{substitute} and \tc{scopesTerm}.

\begin{verbatim}
lemmaSubstituteScopesTerm
  :: s:Subst {ti:Term | isVar ti}
  -> t:Term
  -> { scopesTerm t = scopesTerm (substitute s t) }
\end{verbatim}

The range of the substitution \tc{s} is required to only contain variables, but
this is exactly what \tc{inverseSubst} produces!

\begin{verbatim}
isVar :: Term -> Bool
isVar (V _) = True
isVar _ = False

{-@ inverseSubst :: Subst Term -> {v:Subst {t:Term | isVar t} @-}
\end{verbatim}

Here is the proof of the lemma, which follows the recursive structure
of function \tc{substitute}.

\begin{verbatim}
lemmaSubstituteScopesTerm :: Subst Term -> Term -> ()
lemmaSubstituteScopesTerm s (SA (_, s1)) = lemmaComposeSubstDomain s1 s
lemmaSubstituteScopesTerm s U = ()
lemmaSubstituteScopesTerm s (L t) = lemmaSubstituteScopesTerm s t
lemmaSubstituteScopesTerm s (P t0 t1) =
    lemmaSubstituteScopesTerm s t0 `seq` lemmaSubstituteScopesTerm s t1
lemmaSubstituteScopesTerm s (V v) = case lookupSubst v s of
    { Nothing -> (); Just (V _) -> (); Just _ -> () }
\end{verbatim}

We cut the proof in the case of skolems with an assumption about the
skolems and domains of compositions of substitutions.

\begin{verbatim}
assume lemmaComposeSubstDomain
  :: s0:Subst Term -> s1:Subst {t:_ | isVar t}
  -> {   domain s0 == domain (composeSubst s0 s1)
      && scopesSubst s0 == scopesSubst (composeSubst s0 s1) }
\end{verbatim}


\subsection{Checking \tc{unify}}

In the same way as in the previous section, we start checking the function \tc{unify}
by providing a refinement type signature. This is a rephrasing of the refinement
types of \tc{unifyEq} when the input is a formula instead of a pair of terms. We
drop the third conjunct of \tc{unifyEq} as it is needed only to check \tc{unify} and
it doesn't need to be propagated further.

\begin{verbatim}
unify
  :: {f:Formula | consistentSkolemScopes f}
  -> [(v :: Var
      , { t:Term |
             isSubsetOfJust (freeVars t) (IntMap.lookup v (scopes f))
          && not (Set.member v (skolemSet t))
          && IntMap.isSubsetOf (scopesTerm t) (scopes f)
        }
      )] / [formulaSize f]
\end{verbatim}

The recursion of unify is not structural since in the implication case we
are chaining the recursive calls. Therefore we provide a termination
metric \tc{formulaSize} that counts the amount of connectives in a formula.
We also define a function \tc{scopes} analogous to \tc{scopesTerm} to obtain the skolems
of a formula.

\begin{verbatim}
scopes :: Formula -> IntMap Var (Set Int)
scopes (Forall _ f) = scopes f
scopes (Exists _ f) = scopes f
scopes (Conj f1 f2) = IntMap.union (scopes f1) (scopes f2)
scopes (Then (t0, t1) f2) =
  IntMap.union (scopesTerm t0) (IntMap.union (scopesTerm t1) (scopes f2))
scopes (Eq t0 t1) = IntMap.union (scopesTerm t0) (scopesTerm t1)
\end{verbatim}

We also define the predicate \tc{consistentSkolemScopes}, which ensures that
all occurrences of a skolem have the same domain in their substitutions.

\begin{verbatim}
consistentSkolemScopes :: Formula -> Bool
consistentSkolemScopes (Forall _ f) = consistentSkolemScopes f
consistentSkolemScopes (Exists _ f) = consistentSkolemScopes f
consistentSkolemScopes (Conj f1 f2) =
      consistentSkolemScopes f1
  && consistentSkolemScopes f2
  &&  unionCommutes (scopes f1) (scopes f2)
consistentSkolemScopes (Then (t0, t1) f2) =
     consistentSkolemScopes f2
  && unionCommutes (scopesTerm t0) (scopesTerm t1)
  && unionCommutes (IntMap.union (scopesTerm t0) (scopesTerm t1)) (scopes f2)
consistentSkolemScopes (Eq t0 t1) =
  unionCommutes (scopesTerm t0) (scopesTerm t1)
\end{verbatim}

Liquid Haskell can check mostly automatically the refinement type signature of
\tc{unify}. In the equations for quantifiers, unfolding definitions of
\tc{scopes} plus the refinement type of the recursive calls suffices.
In the equation of conjunction, the theory of arrays of the SMT solver
kicks in to establish the first conjunct of the refinement type:

\begin{verbatim}
unionCommutes (scopes f1) (scopes f2)
=>
(isSubsetOfJust (freeVars t) (IntMap.lookup v (scopes f1)) =>
  isSubsetOfJust
    (freeVars t)
    (IntMap.lookup v (IntMap.union (scopes f1) (scopes f2))))
&&
(isSubsetOfJust (freeVars t) (IntMap.lookup v (scopes f2)) =>
  isSubsetOfJust
    (freeVars t)
    (IntMap.lookup v (IntMap.union (scopes f1) (scopes f2))))
\end{verbatim}

The antecedent of the above goal is established by \tc{consistent\-Skolem\-Scopes}
in the refinement type of the input. The consequent relates the refinement types
of the recursive calls to the expected refinement type of the result, as Liquid
Haskell knows that \tc{IntMap.\allowbreak union (scopes f1) (scopes f2)} stands for
\tc{scopes (Conj f1 f2)}. The second conjunct of the refinement type
is accepted as it is established by the recursive calls and \tc{unifyEq}
as is.

The other equations in \tc{unify} are checked using similar reasoning, all of it
automatic except for a lemma in the implication equation.

\begin{verbatim}
unify f@(Then (t0, t1) f2) =
    let unifsT1 = unifyEq t0 t1
        unifsT1Subst = fromListSubst unifsT1
     in unifsT1 ++ unify (substituteSkolems unifsT1Subst f2)
          ? lemmaScopeSubstSubset (scopes f) unifsT1Subst
\end{verbatim}

The lemma relates the skolems in the substitution \tc{unifsT1Subst}
with the skolems of the input formula.

\begin{verbatim}
assume lemmaScopeSubstSubset
  :: m0:IntMap (Set Int)
  -> s:Subst {t:Term | intMapIsSubsetOf (scopesTerm t) m0}
  -> { intMapIsSubsetOf (scopesSubst s) m0 }
\end{verbatim}

This lemma depends on the representation of substitutions and therefore is
assumed to work as the refinement type signature describes for the sake of
this study.


\subsection{Limitations of Liquid Haskell}
\label{limitations-of-liquid-haskell}

The checking of unification is a plausible future, though one that requires
some enhancements to Liquid Haskell and several bug fixes. Liquid Haskell does
not support reasoning with \tc{Map}s or \tc{IntMap}s at the
moment.\footnote{Issue to support maps in the Liquid Haskell repository: \url{https://github.com/ucsd-progsys/liquidhaskell/issues/2534}} Our
modifications to Liquid Haskell allow us to reason with the type
\tc{IntMap (Set Int)}. While these modifications can be easily adapted to
support other instantiations of \tc{Map a b} or \tc{IntMap b}, a general
solution that can be reused for any instantiation of the type parameters still
needs to be implemented.

There are syntax changes needed in the annotations of Liquid Haskell to support
this, and there is a limitation to overcome in old versions of SMTLIB, the standard
interface to SMT solvers~\cite{BarFT-RR-25} that require user defined functions to
have monomorphic types. While newer versions of the standard allow for polymorphic
types, these still need to be implemented by SMT solvers.

Maps can be implemented with the theory of arrays. An array is an entity that
associates keys with values, and which has an equality predicate.
The implementation of union, intersection, difference, and subset checks, however,
need operations beyond the standard interface, and not all SMT solver can support
them. In our implementation we used the \tc{map} operation of the
Z3 SMT solver. The following snippet contains the implementation of
\tc{intMapIsSubsetOf} in SMTLIB.

\begin{verbatim}
; Similar to Maybe a
(declare-datatype Option (par (a) (None (Some (someVal a)))))

; Similar to do {a0 <- oa0; a1 <- oa1; guard (a0 /= a1); pure a}
(define-fun difference_strict_p2p
  ((oa0 (Option (Set Int)))
   (oa1 (Option (Set Int))))
  (Option (Set Int))
  (match oa0
    ((None None)
     ((Some a0) (match oa1
                  ((None oa0)
                   ((Some a1) (ite (= a0 a1) None oa0))))))))

; Similar to: empty == zipWith difference_strict_p2p xs ys
; where zipWith applies the function pointwise to the values in the
; arrays
(define-fun IntMapSetInt_isSubsetOf
  ((xs (Array Int (Option (Set Int))))
   (ys (Array Int (Option (Set Int)))))
  Bool
  (= ((as const (Array Int (Option (Set Int)))) None)
     ((_ map IntMapSetInt_difference_strict_p2p) xs ys)))
\end{verbatim}

The source code of our unification example lists various defects to fix
in the user experience that required workarounds. A few of them seem to
be about ill-resolved names when translating Haskell identifiers to the
logic language, and there is one example of a function rejected by the
termination checker that should arguably be accepted.

In our code we have been using the simplest possible style of programming.
There are no GADTs, no type families, not even type classes, though
Liquid Haskell has some support for type classes~\cite{liu20}. At the moment,
pushing for more demanding programming patterns is likely to surface more
inconveniences. Aiming for the simplest style is, therefore, a constraint of
the current implementation, unless one is willing to contribute fixes or
look for the workarounds.

On the bright
side, none of the implementation issues that we have encountered in these
examples will require answering open research question.
But for further insight on the challenges of using Liquid Haskell,
Gamboa et al.~\cite{gamboa25} report on a study that collects the voices
of its users.

\section{Evaluation of SMT solvers for interface checks}
\label{SMT-solvers-for-interface-checks}

As the case studies in this paper reinforce, SMT solvers can go a long way in
automating static checks. Insight from the user is necessary, however,
when the properties to check are not handled by any of the theories in the
solver.

When the property involves user defined recursive functions,
sometimes it still can be proved automatically if it is attached to the
refinement type signature of the function. This is the case of the refinement
types of functions \tc{substitute} and \tc{unification}, where the recursion
of the proof supports the inductive reasoning required to established the
property.

When the property cannot be expressed in the signature of a recursive function,
like the lemmas that have been presented, writing lemmas becomes necessary. The
inconvenience is two-fold. In the one hand, the lemma needs to be precisely
written and then demonstrated. And in the other hand, the user needs to figure
out the right set of parameters to apply it to at the sites where it is needed.

These inconveniences are alleviated by the fact that one can still use the
SMT solvers to write abbreviated demonstrations of the lemmas. Additionally,
it would be plausible that one can rely on additional mechanisms to help
discover the parameters to which they are applied. In the case of Liquid
Haskell, there is an implementation of automatic rewrite rules~\cite{grannan22}
that is meant to address the problem for lemmas about equalities.

It would be possible to ask the SMT solver to instantiate the lemma parameters
as needed by introducing assertions with universal quantification. For instance,
the universally quantified lemma \tc{lemma\-FreeVars\-Subst\-Union} follows.

\begin{verbatim}
(assert
  (forall
    ((s (Subst Term))
     (s1 (Set Int))
     (s2 (Set Int)))
    (freeVarsSubst (union s1 s2) s
       == union (freeVarsSubst s1 s) (freeVarsSubst s2 s))))
\end{verbatim}

When checking satisfiability of other assertions, the SMT solver
will try to use the universally quantified assertion. Unfortunately, the
behavior of the procedures to find instantiations for quantified variables are
not easy to predict. This is why Liquid Haskell refrains from doing it~\cite{vazou13}.

On the performance front, all of the SMTLIB queries in the unification example run
in 2 seconds, 0.5 seconds for \tc{Subst3.hs}, and 0.03 seconds in \tc{Subst4.hs}.
That is sometimes faster than it takes to compile the modules with the GHC compiler.
Where things get slower is when measuring Liquid
Haskell, which spends several seconds checking the examples and interacting with the
SMT solver (8 seconds checking unification, 2.5 seconds checking \tc{Subst3.hs},
2 seconds checking \tc{Subst4.hs}). The authors deem that performance of Liquid Haskell
can be improved but likely not below what the SMT solver can deliver.

Other than using an SMT solver in the fashion of Liquid Haskell, F*~\cite{swamy16},
Why3~\cite{filli13}, or Dafny~\cite{leino17},
the alternatives to implementing interface checks are either to encode the checks in
the type-checker, or to migrate to a dependently typed language for the sake of
static checking~\cite{haftmann10, breitner18, carr22}. Of these alternatives,
we feel like using the type-checker is among the most pragmatic. Maclaurin et al. make
a fine demonstration about the foil.

Perhaps one of the biggest compromises when encoding properties in the type-checker
is that one needs to narrow the expressible properties to a feasible set that allows
to write a supporting library. If we wanted to have static checks like those of the
unification example, ensuring that the return terms satisfy the scope check and the
occurs check would require new type encodings. Or in other words, new type indices
need to be conceived to relate the parameters of the function \tc{unify}.
$$\mathit{unify} :: \mathit{Formula}\ f_1 \ldots f_n -> [(\mathit{Var}\ v_1 \ldots v_m, \mathit{Term}\ t_1 \ldots t_r)]$$

Then there would be the effort of writing a library, and later on there would be the
effort of composing the encodings of different libraries when more than one such
is needed. Suppose we wanted to check in the unification example that the
function to apply substitutions passes the static checks of
Section~\ref{capture-avoiding-substitution}. With
refinement types we need to add the corresponding conjuncts to the predicates.

\begin{verbatim}
- substituteFormula
-   :: Set Int
-   -> Subst Term
-   -> f:Formula
-   -> {v:Formula | formulaSize f == formulaSize v}
-
+ type ScopedFormula S = {f:Formula | isSubsetOf (freeVarsFormula f) S}
+ type ScopedTerm S = {t:Term | isSubsetOf (freeVars t) S}
+
+ substituteFormula
+   :: scope:Set Int
+   -> s:Subst (ScopedTerm scope)
+   -> f:ScopedFormula (domain s)
+   -> {v:ScopedFormula scope | formulaSize f == formulaSize v}
\end{verbatim}

Less planning and setup seems necessary when composing refinement types, and
then we can hope SMT solvers to continue to check the same constraints
they were fed when the properties where checked in isolation.

The type-checker approach, however, is likely to produce error messages that
are easier to fix, provided that the user goal is feasible.
The user is guided into correcting the errors
by the types and the operations of the supporting library. With SMT solvers,
there is always the question of whether a goal is provable or not in the
theories at hand. Is there some additional lemma that is necessary about the user defined
functions? The user has to figure it out on her own. How are the assumptions
insufficient to prove the goal? The user has to compute it on her own too,
although it is plausible that counterexamples or better location information~\cite{webbers24}
can be proposed by the tooling when the integration matures.

As an example, let us consider the lemma \tc{lemma\-FreeVars\-Subst\-Union} discussed in
Section~\ref{ensuring-the-scope-set-is-checked}.
If we drop this lemma from the definition of \tc{substitute}, we get the following
error message, heavily edited for presentation.

\begin{verbatim}
tests/rapier/Subst3.hs:141:7: error:
    Liquid Type Mismatch
    The inferred type
      VV : {v : Exp | v == App ?b ?c
                      && freeVars v == union (freeVars ?b) (freeVars ?c)}
    is not a subtype of the required type
      VV : {VV : Exp | freeVars VV == freeVarsSubst (freeVars ?a) s}
    in the context
      ?c : {?c : Exp | ?c == substitute scope s e1
                       && freeVars ?c == freeVarsSubst (freeVars e1) s}

      ?b : {?b : Exp | ?c == substitute scope s e0
                       && freeVars ?b == freeVarsSubst (freeVars e0) s}

      ?a : {?a : Exp | isSubset (freeVars ?a) (domain s)
                       && ?a == App e0 e1
                       && freeVars ?a == union (freeVars e0) (freeVars e1)}

      scope : Set Int
      s : Subst Exp
      e0 : Exp
      e1 : Exp
    Constraint id 33
    |
141 |       App (substitute scope s e0) (substitute scope s e1)
    |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
\end{verbatim}

We can get quickly that the goal is the returned refinement type of \tc{substitute}.
But to get at the missing lemma, we need to calculate with the assumptions that
Liquid Haskell has presented.
To start, we could substitute \tc{freeVars VV} in the goal with what the predicate
in the inferred refinement type defines it to be.

\begin{verbatim}
union (freeVars ?b) (freeVars ?c) == freeVarsSubst (freeVars ?a) s
\end{verbatim}

Then we could substitute the various calls to \tc{freeVars} with what
the refinement types of \tc{?a}, \tc{?b}, and \tc{?c} define them to be.

\begin{verbatim}
union (freeVarsSubst (freeVars e0) s) (freeVarsSubst (freeVars e1) s)
  == freeVarsSubst (union (freeVars e0) (freeVars e1)) s
\end{verbatim}

We have already a first sight of the missing assumption, but to get from
there to the statement of \tc{lemmaFreeVarsSubstUnion}, we still need
to generalize the calls to \tc{freeVars}.

\begin{verbatim}
freeVarsSubst (union s1 s2) s ==
  union (freeVarsSubst s1 s) (freeVarsSubst s2 s)
\end{verbatim}

It is an open question whether we can hope the tooling to effectively
assist these calculations one day.


\section{Conclusions}
\label{conclusions}

We have presented two case studies to contrast the use of SMT solvers
with more traditional approaches based on type checking with strong types. In
our analysis, we tested the ability of SMT solvers to effectively automatize
the static checks otherwise left to the type system.

We found that refinement types enable a direct expression of properties,
particularly when the SMT solver supports the relevant theories. Reasoning
mechanisms are reused from the existing tooling, instead of encoding them
in the type checker. This makes easier both implementing static checks and
composing the properties coming from different sources.

However, integrating SMT solvers for static checks still presents some
challenges. One of them is maturing the existing integrations until they are
feasible to use in industrial setting. Another one is deriving useful
corrective actions from the error messages. And a last challenge is lowering
the checking overhead until it is close to the time required for queries to
the SMT solver alone.

The generality of the approach, and the simplicity with which it enables
composition of different static checks, are unique features that make it a strong
candidate to impact programming practice in the future.

\bibliographystyle{plain}
\bibliography{references}
\end{document}
